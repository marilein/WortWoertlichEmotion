Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Eyben2013,
abstract = {We present recent developments in the openSMILE feature extraction toolkit. Version 2.0 now unites feature extraction paradigms from speech, music, and general sound events with basic video features for multi-modal processing. Descriptors from audio and video can be processed jointly in a single framework allowing for time synchronization of parameters, on-line incremental processing as well as off-line and batch processing, and the extraction of statistical functionals (feature summaries), such as moments, peaks, regression parameters, etc. Postprocessing of the features includes statistical classifiers such as support vector machine models or file export for popular toolkits such as Weka or HTK. Available low-level descriptors include popular speech, music and video features including Mel-frequency and similar cepstral and spectral coefficients, Chroma, CENS, auditory model based loudness, voice quality, local binary pattern, color, and optical ow histograms. Besides, voice activity detection, pitch tracking and face detection are supported. openSMILE is implemented in C++, using standard open source libraries for on-line audio and video input. It is fast, runs on Unix and Windows platforms, and has a modular, component based architecture which makes extensions via plug-ins easy. openSMILE 2.0 is distributed under a research license and can be downloaded from http://opensmile.sourceforge.net/. Copyright {\textcopyright} 2013 ACM.},
address = {New York, New York, USA},
author = {Eyben, Florian and Weninger, Felix and Gross, Florian and Schuller, Bj{\"{o}}rn},
booktitle = {MM 2013 - Proceedings of the 2013 ACM Multimedia Conference},
doi = {10.1145/2502081.2502224},
isbn = {9781450324045},
keywords = {Audio features,Multimodal fusion,Real-time processing,Video features},
pages = {835--838},
publisher = {ACM Press},
title = {{Recent developments in openSMILE, the munich open-source multimedia feature extractor}},
url = {http://dl.acm.org/citation.cfm?doid=2502081.2502224},
year = {2013}
}
@inproceedings{Schotz2007,
abstract = {Speaker age is a speaker characteristic which is always present in speech. Previous studies have found numerous acoustic features which correlate with speaker age. However, few attempts have been made to establish their relative importance. This study automatically extracted 161 acoustic features from six words produced by 527 speakers of both genders, and used normalised means to directly compare the features. Segment duration and sound pressure level (SPL) range were identified as the most important acoustic correlates of speaker age. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Sch{\"{o}}tz, Susanne and M{\"{u}}ller, Christian},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-74122-0_1},
isbn = {9783540741213},
issn = {03029743},
keywords = {Acoustic analysis,Acoustic correlates,Phonetics,Speaker age},
pages = {1--9},
title = {{A study of acoustic correlates of speaker age}},
volume = {4441 LNAI},
year = {2007}
}
@article{Jadoul2018a,
abstract = {This paper introduces Parselmouth, an open-source Python library that facilitates access to core functionality of Praat in Python, in an efficient and programmer-friendly way. We introduce and motivate the package, and present simple usage examples. Specifically, we focus on applications in data visualisation, file manipulation, audio manipulation, statistical analysis, and integration of Parselmouth into a Python-based experimental design for automated, in-the-loop manipulation of acoustic data. Parselmouth is available at https://github.com/YannickJadoul/Parselmouth.},
author = {Jadoul, Yannick and Thompson, Bill and de Boer, Bart},
doi = {10.1016/j.wocn.2018.07.001},
issn = {00954470},
journal = {Journal of Phonetics},
keywords = {Acoustics,Data analysis,Phonetics,Praat,Python,Software},
month = {nov},
pages = {1--15},
publisher = {Academic Press},
title = {{Introducing Parselmouth: A Python interface to Praat}},
volume = {71},
year = {2018}
}
@book{Muller2007,
abstract = {As well as conveying a message in words and sounds, the speech signal carries information about the speaker's own anatomy, physiology, linguistic experience and mental state. These speaker characteristics are found in speech at all levels of description: from the spectral information in the sounds to the choice of words and utterances themselves. The two volume set LNAI 4343 and LNAI 4441 constitutes a state-of-the-art survey for the field of speaker classification approaching the following questions: What characteristics of the speaker become manifest in his or her voice and speaking behavior? Which of them can be inferred from analyzing the acoustic realizations? What can this information be used for? Which methods are the most suitable for diversified problems in this area of research? How should the quality of the results be evaluated? The 19 contributions of the first volume comprise more general and overview-like articles that are organized in topical sections on fundamentals, characteristics, applications, methods and features, as well as evaluation.},
author = {M{\"{u}}ller, Christian},
doi = {10.1007/978-3-540-74200-5},
file = {:home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller - 2007 - Speaker Classification I Fundamentals, Features, and Methods.pdf:pdf},
isbn = {9783540741862},
pages = {362},
title = {{Speaker Classification I: Fundamentals, Features, and Methods}},
url = {http://books.google.es/books?id=APi3{\_}4AV3dkC},
year = {2007}
}
@article{Reubold2010,
abstract = {This paper presents a longitudinal analysis of the extent to which age affects F0 and formant frequencies. Five speakers at two time intervals showed a clear effect for F0 and F1 but no systematic effects for F2 or F3. In two speakers for which recordings were available in successive years over a 50 year period, results showed with increasing age a decrease in both F 0 and F1 for a female speaker and a V-shaped pattern, i.e. a decrease followed by an increase in both F0 and F1 for a male speaker. This analysis also provided strong evidence that F1 approximately tracked F0 across the years: i.e., the rate of change of (the logarithm of) F0 and F1 were generally the same. We then also tested that the changes in F1 were not an acoustic artifact of changing F0. Perception experiments with the main aim of assessing whether changes in F1 contributed to age judgments beyond those from F0 showed that the contribution of F1 was inconsistent and negligible. The general conclusion is that age-related changes in F1 may be compensatory to offset a physiologically induced decline in F 0 and thereby maintain a relatively constant auditory distance between F0 and F1. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Reubold, Ulrich and Harrington, Jonathan and Kleber, Felicitas},
doi = {10.1016/j.specom.2010.02.012},
issn = {01676393},
journal = {Speech Communication},
keywords = {Formants,Longitudinal analysis,Perception,Source-tract-interaction,Vocal aging},
month = {jul},
number = {7-8},
pages = {638--651},
publisher = {Elsevier B.V.},
title = {{Vocal aging effects on F0 and the first formant: A longitudinal analysis in adult speakers}},
volume = {52},
year = {2010}
}
@inproceedings{Burkhardt,
abstract = {This article describes an age-annotated database of German telephone speech. All in all 47 hours of prompted and free text was recorded, uttered by 954 paid participants in a style typical for automated voice services. The participants were selected based on an equal distribution of males and females within four age cluster groups; children, youth, adults and seniors. Within the children, gender is not distinguished, because it doesn't have a strong enough effect on the voice. The textual content was designed to be typical for automated voice services and consists mainly of short commands, single words and numbers. An additional database consists of 659 speakers (368 female and 291 male) that called an automated voice portal server and answered freely on one of the two questions "What is your favourite dish?" and "What would you take to an island?" (island set, 422 speakers). This data might be used for out-of domain testing. The data will be used to tune an age-detecting automated voice service and might be released to research institutes under controlled conditions as part of an open age and gender detection challenge.},
author = {Burkhardt, Felix and Eckert, Martin and Johannsen, Wiebke and Stegmann, Joachim},
booktitle = {Proceedings of the 7th International Conference on Language Resources and Evaluation, LREC 2010},
file = {:home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burkhardt et al. - 2010 - A database of age and gender annotated telephone speech.pdf:pdf},
isbn = {2951740867},
pages = {1562--1565},
title = {{A database of age and gender annotated telephone speech}},
year = {2010}
}
@article{Schotz2007a,
abstract = {Information about the age of the speaker is always present in speech. It is used as perceptual cues to age by human listeners, and can be measured acoustically and used by automatic age estimators. This chapter offers an introduction to the phonetic study of speaker age, with focus on what is known about the acoustic features which vary with age. The age-related acoustic variation in temporal as well as in laryngeally and supralaryngeally conditioned aspects of speech has been well documented. For example, features related to speech rate, sound pressure level (SPL) and fundamental frequency (F 0) have been studied extensively, and appear to be important correlates of speaker age. However, the relationships among the correlates appear to be rather complex, and are influenced by several factors. For instance, differences have been reported between correlates of female and male age, between speakers of good and poor physiological condition, between chronological age and perceived age, and also between different speech sample types (e.g. sustained vowels, read or spontaneous speech). More research is thus needed in order to build reliable automatic classifiers of speaker age. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Sch{\"{o}}tz, Susanne},
doi = {10.1007/978-3-540-74200-5_5},
isbn = {3540741860},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Acoustic analysis,Acoustic correlates,Phonetics,Speaker age},
pages = {88--107},
publisher = {Springer, Berlin, Heidelberg},
title = {{Acoustic analysis of adult speaker age}},
volume = {4343 LNAI},
year = {2007}
}
@misc{sox,
title = {{SoX - Sound eXchange | HomePage}},
url = {http://sox.sourceforge.net/},
urldate = {2020-03-10}
}
@misc{bas,
title = {{BAS CLARIN Repository}},
url = {https://clarin.phonetik.uni-muenchen.de/BASRepository/index.php},
urldate = {2020-03-10}
}
@article{Ryan1974,
abstract = {Direct age estimates of 80 adult male speakers, chronologically 40-80 years of age, were made by 20 untrained listeners from recorded speech samples. Forty recordings were selected for further perceptual and acoustic analyses based upon high listener agreement of perceived age. Judgments by trained listeners of the presence or absence of selected voice characteristics, in addition to five acoustic measurements, were intercorrelated. The significance of these variables in predicting perceived age was assessed through a multiple regression analysis. Results indicated that five voice characteristics-voice tremor, laryngeal tension, air loss, imprecise consonants, and slow rate of articulation-were strong predictors of perceived age, and suggest specific areas of future study involving age related physiologic, acoustic, and perceptual changes in speech production. {\textcopyright} 1974.},
author = {Ryan, W. J. and Burk, K. W.},
doi = {10.1016/0021-9924(74)90030-6},
issn = {00219924},
journal = {Journal of Communication Disorders},
number = {2},
pages = {181--192},
title = {{Perceptual and acoustic correlates of aging in the speech of males}},
volume = {7},
year = {1974}
}
@article{Traunmuller1997,
abstract = {Speech material recorded for the purpose of studying the acoustic properties of speech as a function of speaker sex, age, and vocal effort (induced by varying the distance between speaker and listener over a wide range) was used in perception experiments in which the subjects had to rate either the distance between speaker and listener or the age and the sex of the speaker. The correlations between these percepts and gross spectral and temporal properties of the utterances, such as the mean values of F 0 , F 1 , and F 3 , spectral emphasis and utterance duration were analysed.},
author = {Traunm{\"{u}}ller, Hartmut},
file = {:home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Traunm{\"{u}}ller - 1997 - Perception of speaker sex, age, and vocal effort.pdf:pdf},
journal = {Phonum},
pages = {183--186},
title = {{Perception of speaker sex, age, and vocal effort}},
volume = {4},
year = {1997}
}
@misc{pycharm,
title = {{PyCharm: die Python-IDE von JetBrains f{\"{u}}r professionelle Entwickler}},
url = {https://www.jetbrains.com/de-de/pycharm/},
urldate = {2020-03-10}
}
