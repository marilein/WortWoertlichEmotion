\documentclass[11pt,a4paper,headsepline,twoside,toc=bibliography]{scrreprt}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[latin]{armtex}
\usepackage[ngerman]{babel}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{shorttoc}
\usepackage{booktabs}
\usepackage{listings}
\usepackage[disable]{todonotes}
\usepackage{makecell, multirow}
\usepackage{tcolorbox}
\usepackage{adjustbox}
\usepackage{tipa}
\let\ipa\textipa
\usepackage{vowel}




% Styling
\pagestyle{headings}
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{#1}}

\usepackage{tipa}

\hypersetup{linktoc=all,hidelinks}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\author{Mariam Hemmer}
\title{Interkulturelle Wahrnehmung von Emotionen in Sprache am Beispiel armenischer und deutscher Hörer}

\usepackage{csquotes}
\usepackage[
backend=biber,
style=apa,
alldates=year,
isbn=false,
url=false,
uniquename=init
]{biblatex}


\addbibresource{Masterarbeit.bib}

%\bibliography{Masterarbeit} 

\begin{document}
\begin{titlepage}
\pagenumbering{roman}


\begin{center}
{
\scshape

\includegraphics{siegel}\\[1cm]    

{\LARGE Ludwig-Maximilians-Universität München}

Fakultät für Sprach- und Literaturwissenschaften

Institut für Phonetik und Sprachverarbeitung\\[0.75cm]

{
\HRule \\[0.4cm]

{
\huge \bfseries Interkulturelle Wahrnehmung von Emotionen in Sprache am Beispiel armenischer und deutscher Hörer\\[0.3cm] \large Der Einfluss der Grundfrequenz und des Sprachtempos auf die Wahrnehmung der Emotionen\\[0.4cm]
}

\HRule \\[0.75cm]
}

{
\Large
Masterarbeit\\
Betreuer: PD Dr. Christoph Draxler\\[0.5cm]
Vorgelegt am 20.07.2020\\von Mariam Hemmer\\[0.5cm]
}

Matrikelnummer: 11168853

Hauptfach: Phonetik und Sprachverarbeitung

Adresse: Rembrandtstraße 6, 81245 München

Geburtsdatum: 20.05.1988

}
\end{center}
\cleardoublepage
\end{titlepage}

\chapter*{Erklärung der Eigenständigkeit}

Hiermit erkläre ich, dass ich die vorliegende Arbeit selbstständig und ohne Benutzung anderer als der angegebenen Hilfsmittel angefertigt habe. Alle Stellen, die wörtlich oder sinngemäß aus anderen veröffentlichten und nicht veröffentlichten Quellen entnommen wurden, wurden als solche kenntlich gemacht. Die Arbeit ist in gleicher oder ähnlicher Form oder auszugsweise im Rahmen einer anderen Prüfung noch nicht vorgelegt worden.

\vphantom{M}

\noindent München, den 20.07.2020

\vphantom{M}

\vphantom{M}

\begin{flushright}
$\overline{~~~~~~~~~~~~\mbox{\strut Mariam Hemmer}~~~~~~~~~~~~}$
\end{flushright}


\chapter*{Zusammenfassung}

Interkulturelle Emotionswahrnehmung 

\chapter*{Abstract}
No idea what's that all about.

\cleardoublepage

%\shorttoc{Overview}{0}

\tableofcontents
\listoffigures
\listoftables
\listoftodos
\cleardoublepage

\pagenumbering{arabic}


\chapter{Notizen}
\label{sec:general_notes}
\section{Analysen emotionaler Prosodie, Beate Wendt, 2007}
\begin{itemize}
	
		
	\item Seite 58:
	\begin{itemize}
	
		
		\item überindividuelle Beziehungen zwischen Form und Funktion -> bestimmte Formmuster innerhalb einer Sprachgemeinschaft werden zu bestimmten Bedeutungkomponenten zugeordnet (Neuber 2002)	
	\end{itemize}

	\item Seite 59:
	\begin{itemize}	
		\item Hörexperiment/Wahrnehmungsexperiment - bottom-up vs. top-down Wahrnehmungsprozess 
		\item Analytisches Hören (Viregge 1996) ist relativ (Bose 2003)
		\todo{Viregge 1996, Bose 2003 missing}
	\end{itemize}

	\item Seite 64:
	\begin{itemize}
		\item Die Sprachgeschwindigkeit - keine wichtige Information
	\end{itemize}
	 
	
	\item Seite 70:
	\begin{itemize}
		\item Zur Sprachgeschwindigkeit:\\
		Laut (GWdA 1982) Koartikulation->Leitungsabfall wird in Atem audgeglichen, Leistungssteigung in Artikulation, das ergibt Assimilation und Dessimilation. \todo{ME: Leitungsabfall und Leistungssteigung sind sehr verdächtige Formulierung, lieber nicht benutzen!}
		\todo{Was ist GWdA 1982? Missing anyway!}	
	\end{itemize} 
\end{itemize}


\chapter{Einführung}
\label{sec:einfuehrung}
Menschen reagieren ständig. Die Reaktionen der Menschen sind oft mit Emotionen verbunden. Entweder werden Emotionen durch Reaktionen ausgelöst, oder die Reaktionen entstehen durch ausgelöste Emotionen: die Kontexte sind verschieden, sowie die Theorien (\todo{die Autoren in Psycholinguistik/Neurophysiologie Folien!})
Haben kulturelle Faktoren Einfluss auf die Emotionswahrnehmung? Humor in einer Fremdsprache wird nicht immer las humorvoll wahrgenommen. Zugrunde dessen können verschieden Faktoren liegen. So können kulturell eingeprägte moralische Vorstellungen dararuf einen Einfluss haben, ob ein Witz (\cite{Nevo2001}). Die Studie zeigt, dass Singapurische Studenten konservative Einstellung bezüglich des Inhalts der Witze gezeigt haben. Dahingegen haben amerikanischen Teilnehmern eher Witze gefallen, die agressive Inhalt beinhalteten. In einer verbalen Kommunikation können bestimmte akustische Reize eine Emotion auslösen. So wird Lachen als ansteckend bezeichnet (\cite{Provine1992}). Oder eine Geschichte, die als traurig eingeschätzt wird, kann die Emotion Trauer auslösen. Menschliche verbale Kommunikation kann also sowohl auf der semantischen als auch suprasemantischen Ebene eine Emotionsauslösende Wirkung haben.\\

Verbale Ausdrücke beinhalten Informationen gleichzeitig aus unterschiedlichen Kategorien, wie zumBeispiel Sprecherspezifische Informationen (Geschlecht, Altersgruppe, Dialekt), emotionaler Zustand des Spechers, semantische sowie suprasemantische Inhalte. Diese Kompetenz die enkodierten Informationen in der verbalen Äußerung zu dekodieren kann zwischen Gruppen varieeren. Die Kategorien solcher Gruppen können unter Anderem über Sprache und Kultur definiert werden.

\citeauthor{neuber2002prosodische} weist darauf hin, dass die Sprecher die Fähigkeit haben, durch die für diese Sprache typischen prosodischen Muster, die Emotionen in der gesprochenen Sprache richtig zu interpretieren und für andere Muttersprachler vertändlich auszudrücken. Wenn es angenommen wird, dass eine Sprache über spezifische prosodische Muster für die Emotionswahrnehmung verfügt, dann kann ein Unterschied zwichen Enkodierungs- sowie Dekodierungsmuster zwischen Sprachen erwartet werden (oder möglich, oder zumindest nicht unmöglich).   

Bei dieser Arbeit geht es um interkulturelle Wahrnehmung von Emotionen am Beispiel von deutschen und armenischen Hörern. Dabei wird folgendes untersucht:
\begin{itemize}
	\item die Übereinstimmung der Wahrnehmung von Emotionen in der verbalen Kommunikation bei den deustchen und armenischen Hörern 
	\item der Einfluss der akustischen Merkmale Grundfrequenz und Tempo auf die Emotionswahrnehmung 
\end{itemize}


\chapter{Stand der Forschung}
\label{sec:theory}

Studien zur interkulturellen Emotionswahrnehmung werden in vielen Kontexten durchgefürt. Beispiele dafür sind: 

 \todo{don't forget to cite!}
\begin{itemize}
	\item Gesichtsausdruck
	\item Semantik - schriftliche emotionale Ausdrücke
	\item verbale bedeutungsvolle Ausdrücke
	\item nicht verbale Ausdrücke  
	 
\end{itemize}

\todo{Fritz Artikeln über interkulturelle Emotionswahrnehmung schicken, zum zusammenfassen }
citeautor{Pell2020} haben unter anderem erausgefunden, dass die Gesichtsausdrücke über kulturelle Grenzen hinweg richtig zugeordnet werden können. 


\section{Interkulturelle Zusammenhänge in der Emotionswahrnehmung}
\label{sec:crosscultural_emotion}

In diesem Abschnitt werden die Ansätze in der Forschung hinsichtlich der interkulturellen Emotionswahrnehmung dargestellt. Länder unterscheiden sich unter Anderem aufgrund ihrer Kultur. Die Sprache als Teil der Kultur spielt hier eine sehr große Rolle. Es gibt viele Definitionen für "Kultur". Eine weitverbreitete Definition ist:

	\emph{"Kultur ist die kollektive Programmierung des Geistes, die die Mitglieder einer Gruppe oder Kategorie von Menschen von einer anderen unterscheidet." (\cite[s. 9]{hofstede2001culture} )}

Auch die Ansätze der Forscher, die interkulturelle Studien durchführen, unterscheiden sich. Edward T. Hall (1976) zum Beispiel unterscheidet die Kulturen abhängig von der Art der Kommunikation. Dahingegen werden von manchen Autoren die Kulturunterschiede auf einer mehrdimensionalen Ebene untersucht (\cite{Matsumoto}). Die Dimensionen, die eine Kultur beschreiben sollen, wurden von Hofstede (1980, 1983) vorgeschlagen, da Kulturunterschiede auch innerhalb eines Landes existieren können. Diese Dimensionen bestehen aus ... \todo{F: Hofstedes Dimensionen ?}. 


In vielen Studien werden interkulturelle Vergleiche zwischen Ländern durchgeführt. Der Ansatz, dass Land und Kultur gleichgesetzt werden, kann in vielen bisherigen Studien gesichtet werden\todo{Warum werden Land und Kultur gleichgesetzt?} (zum Beispiel \cite{ekman1973cross}). Manche Experimente haben gezeigt, dass die Wahrnehmung der Emotionen aufgrund von Gesichtsausdrücken im Großen und Ganzen kulturübergreifend ist (\todo{F: find BibTex citations}Ekman 1972, Ekman and Friesen 1971, Ekman, Friesen and Ellsworth 1972, Ekman, Sorenson and Friesen 1969, Izard 1971). In einer weiteren Studie hat Ekman (1987) beschrieben, dass Teilnehmer verschiedener Kulturen die Intensität der Emotionen unterschiedlich bewertet haben. Eine andere Studie konnte feststellen, dass die Intensitätswahrnehmung der Emotionen von den linguistischen Bedeutungsunterschieden in den Kulturen nicht abhängig ist (\cite{matsumoto1989american}). 


\citeauthor{Burkhardt2006} hat die interkulturelle Wahrnehmung von Emotionen  in Frankreich, Deutschland, Griechenland und in der Türkei untersucht \parencite{Burkhardt2006}. Dabei wurden den Teilnehmern semantisch bedeutungsvolle Sätze  präsentiert. Durch die systematische Manipulation der akustischen Merkmale Grundfrequenz, Jitter und Dauer sollte der Einfluss dieser Merkmale auf die Emotionswahrnehmung in oben genannten Ländern untersucht werden. Für jede Sprache konnten merkmalsabhängige Variationen bei der Diskrimination der Emotionen beobachtet werden, nichtsdestotrotz wurden keine signifikanten sprachabhängigen Unterschiede in der Emotionswahrnehmung festgestellt. Dies wird unter anderem dadurch begründet, dass die semantisch bedeutungsvollen Sätze nicht identisch sind, da sie für jedes Land in die jeweilige Sprache übersetzt werden mussten.




Die Beseitigung der linguistischen Faktoren kann in der Forschung dadurch gelöst werden, dass die Semantik in einem verbalen Ausdruck möglichst minimiert wird. Als solches werden oft nonsense-speech, Pseudowörter sowie non-verbale Ausdrücke wie Husten, Lachen oder Weinen,  benutzt. Dabei wird davon ausgegangen, dass die Emotionen durch bestimmte Musterprofile in die gesprochenen Sprache encodiert werden. Um herauszufinden, ob solche encodierten Emotionen unabhängig von Sprache und Kultur erkannt werden können, hat \citeauthor{Scherer2001} ein Perzeptionsexperment in 9 unterschiedlichen Ländern durchgeführt. Dabei wurden Lautkombinationen aus sechs europäischen Sprachen (Deutsch, Englisch, Französisch, Italienisch, Spanisch, and Dänisch) zusammengesetzt. Daraus wurden Sätze formuliert, die von Schauspielern und Schauspielerinnen in sieben prosodischen Ausdrucksweisen ausgesprochen wurden. Neben neutral wurden die Basisemotionen Wut, Freude, Ekel, Angst und Trauer benutzt. \citeauthor{Scherer2001} weist darauf hin, dass zwar kleine kultuabhängige Unterschiede festgestellt wurden, die Accuracy der Emotionserkennung aber in allen Ländern höher war, als es durch Zufall möglich wäre.   

Bei einer anderen Studie wurden die Interpretationen der emotionalen Ausdrücke untersucht (\cite). Wie die Studie abgelaufen ist und was dabei rausgekommen ist.


Hörer können die Emotionen besser zuordnen, wenn diese in ihrer eigenen Sprache ausgesprochen werden (\cite{Pell2020, Chronaki2018}). 

In einer weiteren Studie wurde die interkulturelle Emotionswahrnehmung in der gesprochenen Sprache zwischen neun Ländern untersucht \autocite{Scherer2001}. Hier wurden Sprechausdrücke von deutschen Sprechern als Stimuli benutzt, die keine Bedeutung hatten. Es konnte gezeigt werden, dass die Übereinstimmung bei der Zuordnung der Stimuli zu den erwarteten Emotionen zwischen den Kulturen höher als durch Zufall erklärbar war. Zudem konnte festgestellt werden, dass je weniger Gemeinsamkeiten die Sprache des Höhers mit dem Deutschen hatte, desto geringer die Accuracy bei der Zuordnung der Stimuli zu einer Emotion war. \citeauthor{Scherer2001} weist darauf hin, dass die sprachspezifischen paralinguistischen Eigenschaften vermutlich die Emotionsverarbeitung beeinflüssen können.



\section{Sprachperzeption}
\label{speech_perception}

Sprache ist das Hauptmittel der menschlichen Kommunikation. Unter Kommunikation versteht man den Informationsaustausch zwischen zwei oder mehreren Individuen. Dabei handelt es sich um einen Prozess, an dem mindestens zwei 'Parteien' beteiligt sind. Einer erzeugt die Information und gibt sie an den Partner weiter, der wiederum nimmt die Information wahr und verarbeitet diese. Bei der verbalen Kommunikation sind die Parteien dieses Prozesses der Sprecher und der Hörer, wobei der Sprecher encodierte Informationen durch die verbalen Ausdrücke an den Hörer weiter gibt. Die Informationen wird zunächst perzepiert und anschließend dekodiert. Wenn unter Dekodierung der Informationen in einem verbalen Ausdruck dessen Zerlegung in Informationsklassen verstanden wird, können diese Klassen wie folgt aussehen:

\begin{itemize}
	\item nicht-verbale: Informationen über den Sprecher, wie Alter, Geschlecht, Herkunft usw.
	\item semantische (oder eher verbale linguistische)
	\item parasemantische (oder eher verbale paralinguistische)
\end{itemize}

Das menschliche Gehör besteht aus drei Teilen: Außenohr, Mittelohr und Innenohr (\todo{texthier kommt das bekannte Bild}). Das Außenohr dient als Antenne, welche die empfagenen akustischen Reize verstärkt und an das Mittelohr überträgt. Hier werden die Reize durch Ambus und Hammer an das Innenohr übertragen. Die Verarbeitung der Frequenzen im Innenohr übernimmt die Cochlea - die Hörschnecke (\todo{ier kommt ebenfalls ein bild}). \todo{Detaillierte Schilderung der Membrane und Bahnen und Haarzellen folgt noch!} Unterschiedliche Teile der Cochlea sind für unterschiedliche Frequenzbereiche zuständig (hier kann natürlich auch ein bild der Cochlea mit der Zuteilung der Frequenzbereiche). Die durch die Basilarmembran empfangenen Frequenzen werden in ein elektrisches Signal umgewandelt und als Nervenimpuls an das Gehirn weitergeleitet. \todo{Hier können die Hörbahnen erklärt werden}. Anschließend reagieren die Gehirnareale, die an der Sprachperzeption beteiligt sind auf den Impuls und verarbeiten diesen. So wird zum Beispiel die Phonemerkennung im Brocca-Areal durchgeführt, während im Wernicke-Areal nach der Bedeutung dieser Lautkombination gesucht wird. \\




Die akustischen Reize werden durch das Ohr wahrgenommen. Bereits das Außenohr verstärkt den empfangenen Schall und überträgt durch das Trommelfell (Ambus und Hammer) \\


\section{Emotion in Sprache}
\label{sec:emotion_in_speech}



\emph{Klassifizierung von Emotionen}
Es gibt drei Modelle der Klassifizierung der Emotionen \autocite[s. 46]{Wendt2007}. \\

\emph{Dimensionsmodell}
...

\emph{Basisemotionen}
Der Magdeburger Sprachkorpus beinhaltet die Basisemotionen Freude, Trauer, Wut, Ekel, Angst sowie neutral. Im Sprachkorpus sind die neutralen Sprachaufnahmen als 'sachlich' vermerkt (\cite{Wendt2002}). Im Sprachkorpus befinden sich deutsche Wörter, die in diesen Basisemotionen von einem Schauspieler und von einer Schauspielerin gesprochen wurden. Außerdem wurden aus diesen Wörtern Pseudowörter durch Umpositionierung der Laute erstellt, welche ebenfalls von den selben Schauspielern in obengenannten Emotionen ausgesprochen wurden. Die kreierten Pseudowörter entsprechen der deutschen Phonotaktik. In einem Perzeptionsexperiment wurden die ausgesprochenen Emotionen evaluiert (\cite{Wendt2003}). \\

Emotionen haben einen großen Einfluss auf die Grundfrequenz. Wenn der Sprecher traurig ist, ist seine Grundfrequenz eher niedriger, als wenn derselbe Sprecher glücklich oder wütend ist. Das hat physiologische Gründe. Zum Beispiel bei Wut oder Freude werden bestimmte Muskeln angespannt, die an der Sprachproduktion teilnehmen. Durch die Anspannung der Muskeln ändert sich die intrinsische Grundfrequenz. \\

-Komponenten-Prozess-Modell 
\todo[inline, color=red!40]{Scherer 1990, Paeschke 2003 missing!}
Reizbewertungsprüfung hat Einfluss auf das Nervensystem. Dadurch entsteht eine ganz bestimmte Veränderung der Muskelanspannung: diese Änderungen betreffen auch die Muskeln der Stimmproduktion (Paeschke 2003).\\

Dieser Vorgang betrifft die Fälle, wenn die Emotionen auf einer natürlichen Weise entstehen und einen Einfluss auf die Sprachproduktion haben. Jetzt ist die Frage, ob es möglich ist Emotionen zu spielen und diesen natürlichen Vorgang der Prosodieänderung bei der emotionalen Sprache nachzuahmen. 

\emph{ABER}: die Stimuli oder die Emotionen der Stimuli sind nicht durch eine natürliche Reizbewertungsprüfung der Sprecher zu Stande gekommen, sondern wurden durch die Schauspieler entsprechend ihrer subjektiven Vorstellung produziert. Diese Stimuli wurden dennoch durch Perzeptionsexperimente validiert.\\



\section{Prosodie}
\label{sec:prosody}

Die menschliche Kommunikation ist sehr vielschichtig. Die gesprochene Sprache enthält einerseits den konkreten Inhalt, was gesagt wird, andererseits vermittelt sie ebenso die Einstellung und das Verhältnis des Sprechers zum Inhalt des Gesagten - also wie etwas gesagt wird. Oft ist die Information darüber, wie etwas gesagt wird, sogar viel wichtiger für den Hörer, als der Inhalt an sich (\textcite{Wildgruber2006}). Hinsichtlich der verbalen Kommunikation wird diese suprasemantische Information in der gesprochenen Sprache encodiert und durch akustische Cues vermittelt. Die Stimmqualität, der Intonationsverlauf der Stimme, sowie Variationen in der Tonhöhe und der rythmischen Struktur, wie zum Beispiel das Sprechtempo, geben Hinweise über den emotionalen Zustand des Sprechers. Diese Hinweise dienen für den Hörer als akustische Korrelate bei der Wahrnehmung der affektiven Prosodie \todo{zitieren: (Scherer 1986; Scherer et al. 2009; Sidtis \& Van Lancker Sidtis 2003}. 

Die Details hierzu werden im nächsten Kapitel behandelt. \\  

Bei der Prosodieverarbeitung im Gehirn ist die rechte Hemisphäre mehr beteiligt, als die linke Hemisphäre \parencite{Ackermann2014c} .  

\section{Akustische Merkmale}
\label{sec:prosody_features}

Welche Merkmale können die Emotionswahrnehmung beeinflussen? Wie werden diese Merkmale wahrgenommen und verarbeitet? Sprachperzeption ist ein komplexer Prozess, bei dem mehrere Areale sowohl in der rechten als auch in der linken Hemisphäre des Gehirns beteiligt sind. Nichtsdestotrotz werden die wahrgenommenen Reize vorwiegend einseitig verarbeitet, da die Hemisphären nicht gleichermaßen für alle Verarbeitungsprozesse spezialisiert sind. Auch bei der Sprachverarbeitung findet eine Lateralisierung der Informationsverarbeitung im Gehirn statt. Zur Funktionalität der linken Hemisphäre zählen zum Beispiel manche Aspekte der semantischen und der phonologischen Informationsverarbeitung. Die rechte Hemisphäre ist sowohl für den Intonationsverlauf, als auch für weitere suprasemantische Aspekte der Sprachverarbeitung zuständig. Der Intonationsverlauf kommt durch die Variation der Grundfrequenz zustande. Die Grundfrequenz als ein sehr wichtiges akustisches Merkmal vermittelt Informationen darüber, wer der Sprecher ist und wie der Sprecher spricht. Außer Hinweisen über Geschlecht und Alter des Sprechers beinhaltet die Grundfrequenz auch Informationen über die Intentionen und den emotionalen Zustand des Sprechers. \\

Eine Studie zeigt, dass der Verarbeitungsprozess der Grundfrequenz durch die Lateralisierung der rechten Hemisphäre zugeteilt wird (\cite{VanLancker1973a}). \\





Die Produktion und die Perzeption der emotionalen Sprache wird im Wesentlichen durch drei Merkmale beinflusst (\cite{Scherer2001})

\begin{enumerate}
	\item Grundfrequenz: Variation des Intonationsverlausf bei unterschiedlichen Emotionen 
	\item Sprachtempo: Bei manchen Emotionen redet man schneller oder langsamer, ein Beispiel wäre Traurigkeit, wo das Tempo verlangsamt wird, im Gegensatz zu wütend, wo das Tempo erhöht wird.
	\item Intensität
\end{enumerate}







Diese Merkmale beeinflussen die emotionale Sprachproduktion und dienen für den Hörer als akustische Cues für die Emotionswahrnehmung. Bei der emotionalen Sprachproduktion ... 
Studien zeigen eine Tendenz, dass die Grundfrequenz, gefolgt vom Merkmal Sprachtempo
einen starken Einfluss auf die Emotionswahrnehmung hat. \citeauthor{Banse1996} erwähnt eine starke Korrelation zwischen Grundfrequenz und Intensität basierend auf dem physiologischen Prozess der Sprachproduktion: der subglottale Druck führt zur Muskelanspannung, durch die sowohl die Grundfrequenz als auch die Intensität steigen.\\



\subsection{Grundfrequenz}

Die Grundfrequenz (F0) ist die Frequenz der Glottisschläge, die beim Sprechen durch die Bewegung der Stimmlippen erzeugt werden. F0 wird in Hertz (Hz) gemessen. Die Grundfrequenz wird in der gesprochenen Sprache als Intonationsverlauf wahrgenommen. 

\begin{figure}
	\centering
	\begin{subfigure}{1\textwidth}
		\centering
		\includegraphics[width=0.8\linewidth]{pics/sawet_s.png}
		\caption{neutral}
		\label{fig:sawet_s}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{0.8\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{pics/sawet_T.png}
		\caption{Trauer}
		\label{fig:sawet_T}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{0.8\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{pics/sawet_F.png}
		\caption{Freude}
		\label{fig:sawet_F}
	\end{subfigure}
	\caption{\textbf{Intonationsverlauf für verschiedene Emotionen.} das Wort \emph{sawet} (IPA: \textipa{[zavEt\super{h}]}) ausgesprochen von dem selben Sprecher (männliche Stimme) in prosodischen Ausdrucksweisen  neutral(a), Trauer(b) und Freude(c). Der Durchschnittswert der Grundfrequenz beträgt 106 Hz für den neutralen prosodischen Ausdruck (a), 80 Hz für Trauer(b) und 108 Hz für Freude(c).}
	\label{fig:pitch_variation}
\end{figure}


\subsection{Sprachtempo}

Das Sprachtempo bezeichnet das Verhältnis der Dauer von der verbalen Äußerung zu verschiedenen sprachlichen Einheiten, wie zum Beispiel Silbe oder Wort \autocite{Ackermann2004}.  

Die Wahrnehmung der Variationen des Sprachtempos in der gesprochenen Sprache ist sehr wichtig für die Sprachverarbeitung im Gehirn. Die Änderung der Aufmerksamkeit der Hörer im Bezug zum Sprachtempo wurde durch perzeptive Experimente belegt (\todo{cite !!!}) \\ 
 

 
Viele Studien zeigen, dass die Hörer auf die Variation der Dauer und Geschwindigkeit der Stimuli reagieren. Die Annahme, dass die Variation der Dauer Auswirkung auf die Emotionswahrnehmung hat, konnte in manchen Studien belegt werden (Scherer 2005?, 2011?). Andere Experimente konnten diese Verbindung nicht eindeutig belegen (\cite{Schirmer2016a})\\

Die Emotionen beeinflussen die Sprachproduktion, da die physiologischen Abläufe, die bei Emotionen entstehen nicht immer unterdrückt oder kontrolliert werden können. Aus der Perspektive der Beschreibungsdimensionen Valenz und Erregung betrachtet, kann die letztere unter Anderem die Frequenz des Herzschlags und die Muskelanspannung beeinflussen. Dies führt zu Änderungen der akustischen Merkmale, die durch den Hörer im Zusammenhang mit den Emotionen verarbeitet werden \parencite{Schirmer2016a}. Damit der Hörer im Stande ist die gehörten Emotionen richtig zu dekodieren, ist zu erwarten, dass die verbalen Ausdrücke eindeutige Hinweise für den Hörer liefern, der dadurch den prosodischen Ausdruck des Sprechers dieser oder jener Emotion zuordnen kann.  In vielen Situationen kommt es dazu, dass diese physiologischen Abläufe ein emotionales Muster im Sprachausdruck hinterlassen. So ist zum Beispiel das Sprachtempo bei Freude eher schneller, während es eher langsamer ist, wenn der Sprecher traurig ist. 
 



\bigskip

Experiment Design
Experiment als Webexperiment durchgeführt.
Zum designen eines Online-Experimentes bietet sich die Percy-Software (\cite{Draxler2011}) an, da hier die Vorlagen für das Design an die Anforderungen des jeweiligen Experimentes individuell angepasst werden können.


\subsection{Intensität}
\label{intensity}

Intensität als akustischer Merkmal wird durch Amplitude dargestellt. 



\section{Diskussion}
\label{sec:method_discussion}

Spruchproduktion ist ein komplexer Prozess, der sowohl semantische als auch suprasemantische Information überträgt. 



\chapter{Emotion und Sprache -  das Experiment}
\label{sec:experiment_overview}

In der vorliegenden Studie geht es um die Emotionserkennung in der gesprochenen Sprache. Aus diesem Grund soll die gemeinsame Sprache einer Gruppe im Rahmen dieser Arbeit als Bedingung dafür dienen, diese Gruppe als eine Kultur zu definieren. Hinsichtlich der sprachlichen Aufteilung werden die Teilnehmer dieser Studie aufgrund ihrer Muttersprache zu einer Kultur zugeordnet.  

Die Emotionswahrnehmung in der gesprochenen Sprache kann durch ein Perzeptionsexperiment evaluiert werden. Die Messkriterien für die Wahrnehmung der Emotionen können entweder numerisch oder kategorial sein. Im ersteren Fall müssen die Hörer die wahrgenommene Emotion auf einer Skala mit einer numerischen Eingabe bewerten. In diesem Fall können auch die Variationen der Perzeption innnerhalb derselben Emotion analysiert werden. Eine gängige Methode ist dabei die Messung der Valenz und der Erregung im emotionalen prosodischen Ausdruck. 

Bei der kategorialen Methode müssen die Hörer den Stimulus einer Kategorie zuordnen. Diese Kategorien können zum Beispiel Emotionen darstellen (Wut, Trauer, Freude usw.) oder als positive, negative und neutrale Emotionen zusammengefasst werden. Für die Untersuchung der Emotionswahrnehmung von deutschen und armenischen Hörern wurde die kategoriale Methode ausgewählt. Die Gründe für diese Auswahl werden im Folgenden detailliert erläutert.


Im Rahmen dieser Arbeit wurde ein Web-Experiment in zwei Sprachen vorbereitet - armenisch und deutsch. Die Teilnehmer wurden nach soziodemographischen Daten gefragt, wie Geschlecht, Alter und das Land, in dem sie wohnen. Außerdem gab es Fragen zur Persönlichkeit, die nach dem Fünf-Faktoren-Modell (Big Five) vorbereitet wurden (siehe \ref{appendix:bigfive}). Zu jeder dieser darin enthaltenen Dimension gab es eine Frage (Offenheit, Verträglichkeit, Extraversion, Gewissenhaftigkeit, Neurotizismus). Die Übersetzung dieser Fragen ins Armenische wurde selbstständig durchgeführt, da keine evaluierte Version des Fragebogens, die für wissenschaftliche Recherche offen zur Verfügung stand, vorhanden war. Die deutsche Version des Fragebogens zur Persönlichkeit ist im Anhang \ref{appendix:bigfive} zu finden. 



\section{Motivation}
\label{sec:experimemnt_motivation}

\todo{hier muss noch Text rein}

Was ist mit Hypothesen? Ich glaube diese sollen genau hier rein. Also mindestens 2 Hypothesen:\\

(H1) interkulturelle Unterschiede bei Originalsprachaufnahmen

(H2) F0 und Tempo Manipulation haben für manche Emotionen (vielleicht bei den Emotionen, die schlecht von den Armeniern identifiziert werden) abhängig von der Kultur Unterschiedliche Auswirkungen auf die Emotionswahrnehmung.  

\section{Methodik}
\label{sec:method}

Für das in dieser Arbeit beschriebene Perzeptionsexperiment wurden Stimuli benötigt, welche durch den Hörer evaluiert werden können. Die Stimuli wurden von den deutschen und armenischen Hörern annotiert. Da die Stimuli für beide Gruppen dieselben Sprachaufnahmen waren, sollten die Pseudowörter, die als Stimuli benutzt wurden, sowohl der deutschen als auch der armenischen Phonotaktik entsprechen. Die Prüfung nach der Legalität der Lautkombinationen für die deutschen Hörer wurde bei der Erstellung des Magdeburger Prosodie-Korpus, aus welchem die Pseudowörter ausgewählt wurden, durchgeführt (\cite{Wendt2002}). Der Korpus ermöglicht einen Einblick in die Emotionswahrnehmung der gesprochenen Sprache bei den deutschen Hörern. Dies dient als Grundlage für den hier thematisierten Vergleich der Emotionswahrnehmung zwischen armenischen und deutschen Hörer in einem interkulturellen Kontext.\\

Bei der Auswahl der Wörter für das Experiment wurde geprüft, ob die Lautkombinationen und Silbenstrukturen der Phonotaktik der armenischen Sprache entsprechen (siehe \autoref{sec:pseudowords})\\


Um dies zu untersuchen sind mehrere unterschiedliche Methoden denkbar, die sich sowohl in ihrer Aussagekraft als auch in ihrer Durchführbarkeit unterscheiden.\\

Bei einer Methode werden die manipulierten Stimuli anhand vorgegebener Kategorien, wie zum Beispiel der Intensität einer Emotion, auf einer Skala bewertet. Da diese Arbeit aber das Ziel hat, die Wahrnehmung der Emotionen zu untersuchen, würde dies durch diesen Ansatz gerade durch die Vorgabe der Kategorien verhindert werden.\\

Eine andere Methode würde sowohl die Auswahl der Kategorie als auch die Bewertung auf einer Skala dem Probanden überlassen. Durch diesen Anstieg an Freiheitsgraden stiege aber auch die Dimensionalität der Daten, wodurch auch die Anzahl der Stichproben drastisch gesteigert werden müsste, um eine statistische Signifikanz zu erreichen. Dies würde den Rahmen dieser Arbeit übersteigen.\\

Deshalb wurde eine Methode ausgewählt, die Stimuli nicht willkürlich sondern gezielt manipuliert und diese dann vom Probanden einer vorgegebenen Liste von Emotionskategorien zugeordnet werden sollen. Dadurch wird sichergestellt, dass der Hörer die Entscheidung trifft, welcher Emotion er das Sprachsignal zuordnet. Auf der anderen Seite bleibt das Experiment relativ übersichtlich und mit der realistisch erwartbaren Stichprobenpopulation statistisch auswertbar.

\subsection{Auswahl der Merkmale}

Die für die Emotionswahrnehmung wichtigen akustischen Merkmale sind Grundfrequenz, Sprachtempo und Intensität (siehe \ref{sec:prosody_features}). Bisher wurden diese Merkmale in unterschiedlichen Kontexten untersucht. \todo{Systematische vs nicht-systematische Manipulation der Merkmale : Beispielstudien zitieren.}

 
Durch die systematische Synthese der akustischen Merkmale Grundfrequenz, Sprachtempo und Intensität konnte die Sensibilität der Hörer bezüglich der Merkmale als akustischer Cue in Bezug auf die Emotionswahrnehmung getestet werden. Die isolierte Präsentation der manipulierten Merkmale hat gezeigt, dass Grundfreuquenz und Sprachtempo am stärksten die Wahrnemung der Emotionen in Sprache beeinflussen \autocite{Lieberman1962}.  Außerdem konnte eine relativ starke Korrelation (r=.62) des Durschnittswertes der Grundfrequenz mit dem Durschnittswert der Energie in emotionalen Sprachsignalen gezeigt werden \autocite{Banse1996}.\\

Auf Grund der Befunde, dass die Grundfrequenz stark mit der Intensität korreliert, sowie der relativ niedrigen Priorisierung der Intensität für die Emotionswahrnehmung, wird in dieser Studie der Einfluss untersucht, der eine Änderung der Grundfrequenz oder des Sprachtempos auf die Emotionswahrnehmung in einem interkulturellen Kontext hervorrufen kann.



\subsection{Auswahl des Sprachkorpus}
\label{sec:db}

Es ist schon lange bekannt, dass die semantische Verarbeitung der Sprache weitgehend in der linken (oder eher in der dominanten) Hemisphäre geschieht. Dahingegen werden manche Aspekte der suprasemantische Ebenen der gesprochenen Sprache in der rechten oder nicht dominanten Gehirnhälfte verarbeitet. Zur Suprasemantik der gesprochenen Sprache zählt auch die Emotionswahrnehmung, die in dieser Arbeit untersucht wird. Die semantische Verarbeitung der Sprache kann einen Einfluss auf die Emotionswahrnehmung haben. So kann ein Wort mit einer positiven Bedeutung mit einer negativen Emotion ausgesprochen werden. Die Bedeutung des Wortes kann in diesem Fall als Störfaktor für die Emotionswahrnehmung bezeichnet werden, da die Semantik einen Einfluss auf die Verarbeitung der emotionalen Information hat, die durch Prosodie vermittelt wird. In dieser Arbeit steht die Emotionswahrnehmung im Fokus. Außerdem sollten die gleichen Bedingungen für die Hörer der zu vergleichenden Kulturen bei der Präsentation der Stimuli geschaffen werden. Da im Rahmen dieser Arbeit die interkulturelle Wahrnehmung der deutschen und armenischen Hörer untersucht wird, sollten die Stimuli sowohl auf Armenisch als auch auf Deutsch keine Bedeutung haben. Daher sollte die Semantik der Stimuli als Störfaktor betrachtet werden. Für diesen Zweck sollten also Sprachaufnahmen als Stimuli in Frage kommen, die keine Bedeutung haben.  Die Anforderungen dieser Studie für den Sprachkorpus können wie folgt zusammengefasst werden: 


\begin{itemize}
	\item der Sprachkorpus enthält emotionale Sprache
	\item die Ausdrücke sollten mindestens von einem Sprecher und einer Sprecherin gesprochen werden 
	\item der selbe Text ausgesprochen in allen Emotionen, die im Sprachkorpus enthalten sind
	\item mindestens folgende Basisemotionen sind enthalten: Freude, Wut, Trauer, Angst und neutral
	\item die Stimuli sollen möglichst kurz sein, eher Wörter als Sätze, da je länger der Stimulus ist, desto mehr  Informationen im Sprachsignal enhalten sind. Daher kann zu viel Information ein Störeffekt für die Prosodieverarbeitung hinsichtlich der Emotionen sein.
	\item die Stimuli stammen aus einer evaluierten Sprachdatenbank
\end{itemize}


Das Bayerische Archiv für Sprachsignale (BAS: \url{https://www.bas.uni-muenchen.de/Bas/BasHomedeu.html}) stellt Sprachdatenbanken zur Verfügung, die für die Forschung benutzt werden können. Es wurde geprüft, welche der vorhandenen Sprachdatenbanken die obengenannten Bedingungen für diese Untersuchung erfüllen. Ein Subset des Magdeburger Prosodie-Korpus ist WaSeP (Gesprochenes Wortkorpus für Untersuchungen zur auditiven Verarbeitung
von Sprache und emotionaler Prosodie). Dieser Korpus wird von BAS bereitgestellt und entspricht den gesetzten Vorraussetzungen. Daher wurde WaSeP für diese Arbeit verwendet. \\
 

\subsection{Der Magdeburger Prosodie-Korpus}

Der Magdeburger Prosodie-Korpus besteht aus zwei Sprachdatenbanken. Die eine enthält deutsche Substantive, die zweite besteht aus Pseudowörtern. Beide Teile wurden von einem Mann und von einer Frau ausgesprochen. Bei den  Sprechern handelt es sich um professionelle Schauspieler, die die vorgegebenen Emotionen simuliert haben \autocite[s. 86]{Wendt2006} .  Durch Perzeptionsexperimente wurde die Akzeptanz der Emotionen in Sprachaufnahmen untersucht \autocite{Wendt2003}.

Die Sprachsignale (RIFF Wave, mono, 44.1kHz,16bit) im Korpus sind nach folgendem Schema benannt:  Sprechergeschlecht\_Sprachausdruck\_Emotion. Beispiel: F\_misuk\_A.wav, wobei das Wort "misuk" von einer Frau mit dem prosodischen Ausdruck "Angst" ausgesprochen wird.\\
 
Der Magdeburger Prosodie-Korpus beinhaltet Sprachaufnahmen in folgenden Basisemotionen: Freude, Wut, Angst, Trauer, Ekel sowie neutral. 

Für die Untersuchung der interkulturellen Emotionswahrnehmung musste die Emotionswahrnehmung im Mittelpunkt stehen. Daher sollten möglichst wenige Störfaktoren vorhanden sein. Ein sehr wichtiger Störfaktor für die Untersuchung der Emotionswahrnehmung ist die Verarbeitung der semantischen Aspekte der Sprachperzeption im Gehirn, da die Semantik ebenfalls Emotionen auslösen kann. Aus diesem Grund sollte die Prosodie der Stimuli der Hauptinformationsträger für die Emotionen sein. Daher hat sich die Sprachdatenbank, die aus Pseudowörtern erstellt wurde als sehrt gut für diese Arbeit geeignet herausgestellt. 

Die Validierung der ausgesprochenen Emotionen in den Sprachaufnahmen wurde durch Perzeptionsexperimente mit phonetisch ungeschulten Hörern sowie mit phonetisch geschulten Experten durchgeführt. Bei den insgesamt 74 ungeschulten Teilnehmern befanden sich 37 weibliche und genau so viele männliche Hörer, deren Alterspanne von 18 bis 62 Jahren mit einem Durchschnittsalter von 30,15 Jahre war \autocite[s. 104]{Wendt2007}. Bei den Experten handelte es sich um drei Teilnehmerinnen und einen Teilnehmer. Die Ergebnisse der Evaluation der prosodischen Ausdrücke weisen eine Akzeptanz der Emotionen über 70 Prozent auf. Eine Ausnahme ist der prosodische Audruck Trauer in Pseudowörtern, die von dem männlichen Schauspieler ausgesprochen wurden (\ref{fig:wasep_evaluation}).

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{pics/wasep_evaluation.png}
	\caption{\textbf{Die Akzeptanz der ausgesprochenen Emotionen bei allen Hörern (aus \cite{Wendt2002}).}}
	\label{fig:wasep_evaluation}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{plots/speaker_f0/speaker_f0.png}
	\caption{\textbf{Die durschnittlichen Grundfrequenzwerte des Sprechers (links) und der Sprecherin (rechts) pro Sprachsignal.} Die Sprachsignale sind nach prosodischen Ausdrücken gruppiert und in unterschiedlichen Farben dargestellt. Für jeden Sprecher sind es vier Sprachaufnahmen für jede Klasse der Emotionen. Jede Sprachaufnahme entspricht einem der vier ausgewählten Pseudowörtern, die als Grundlage für die Stimuli dienten (siehe \autoref{sec:pseudowords}). }
	\label{fig:speaker_f0}
\end{figure}


\todo{folgenden Absatz bearbeiten, sortieren, löschen}
Es wurde entschieden Stimuli aus der Sprachdatenbank mit den Pseudowörtern auszuwählen, da diese keine Bedeutung weder für Deutsche noch für Armenier haben (\autoref{sec:pseudowords}). Also können die Hörer durch die semantische Bedeutung nicht abgelenkt werden, und dadurch kann bei der Verarbeitung im Gehirn mehr Aufmerksamkeit auf die Emotionswahnermung gelegt werden. Die Auswahl der Stimuli aus diesen Pseudowörtern wurde folgendermaßen durchgeführt: alle 200 Pseudowörter, die im Korpus enthalten sind, wurden zunächst auf die armenische Phonotaktik geprüft. Bei dieser Prüfung konnte ein Großteil der Wörter bereits ausgeschlossen werden. Zum Beispiel gab es manche Wörter, die einem armenischen Wort ähnlich waren.  Viel Pseudowörter kamen als Stimuli nicht in Frage, weil sie mit einem Vokal beginnen. Diese Wörter werden von deutschsprachigen Personen mit einem stimmlosen glottalen Plosiv ausgesprochen. Auf Armenisch gibt es nicht zwingend einen stimmlosen glottalen Plosiv vor einem Vokal am Wortanfang. Daher wurden alle Wörter herausgefiltert, die mit einem Vokal anfangen. Außerdem gibt es Pseudowörter,die Phoneme enthalten, die im armenischen Phoneminventar (\autoref{appendix:alphabeth_am}) nicht vorhanden sind. Alle Wörter, die Laute enthalten, die nicht im armenischen Phoneminventar vorkommen oder nicht als Allophone eines Phonems wahrgenommen werden, wurden von der Auswahl ausgeschlossen. Endlich wurden noch alle Wörter die Klaster haben, die im Armenischen nicht legal sind, ebenfallls herausgefiltert. Am Ende blieben 15 Wörter, die der armenischen Phonotaktik entsprachen. Aus diesen 15 Wörtern wurden die Stimuli vorbereitet, d.h. die Manipulationen für F0 und Tempo wurden durchgeführt, und nach einer erneuten Prüfung der Stimuli, wurden diejenigen gelöscht, die nach der Resynthese Artefakte hatten. Am Ende sind vier Stimuli übriggeblieben, die für das Experiment in Frage kamen, also alle geforderten Kriterien erfüllen. Als Artefakte wurden zum Beispiel Verzehrungen in der Stimme gewertet, wodurch das Sprachsignal nicht miteinbezogen werden konnte. \todo{kpieren zur Wortauswahl}

\section{Stimuli}
\label{sec:stimuli}

Die Emotionswahrnehmung in der gesprochenen Sprache kann durch die semantische Bedeutung beeinflusst werden. Da die Pseudowörter keine Bedeutung auf Deutsch haben, waren diese als Stimuli geeignet. Es befanden sich 200 Pseudowörter im Sprachkorpus, die zunächst detailliert untersucht wurden, um daraus die Stimuli auszuwählen. Für diese Auswahl mussten die Pseudowörter folgende Bedingungen erfüllen:

\begin{itemize}
	\item das Wort hat keine Bedeutung auf Armenisch
	\item das Wort enthält nur Phoneme, die im Armenischen als Phoneme oder als Allophone vorkommen
	\item das Wort entspricht der armenischen Phonotaktik
	\item nach der Manipulation des Sprachsignals entstehen keine Artefakte 
\end{itemize} 

Die armenische Sprache war ein Prüfkriterium bei der Auswahl der Pseudowörter, die als Stimuli sowohl den deutschen als auch den armenischen Hörern präsentiert werden sollten. Daher wird im nächsten Kapitel die Phonetik und Phonologie der armenischen Sprache dargestellt.

\section{Phonetik und Phonologie der armenischen Sprache}
\label{armenian_phonology}

Die Silbenstruktur der armenischen Sprache wurde zwar von armenischen Linguisten in mehreren Studien untersucht (\todo{armenische Linguisten zitieren, die über Silbenstruktur geschrieben haben}), allerdings wird der Fokus dabei immer auf die Orthographie gelegt. Dabei wird die gesprochene Sprache nur im Zusammenhang mit den jeweiligen Formen der schriftlichen Sprache diskutiert. Obwohl das Graphem-Phonem-Verhältnis überwiegend übereinstimmt und jeder Phonem mindestens einem Graphem entspricht, besteht allerdings kein 1:1 Verhältnis zwischen den Phonemen und Graphemen in der modernen armenischen Standardsprache (siehe Anhang \ref{appendix:alphabeth_am}). Das heisst, es gibt Phoneme, die durch mehr als ein Graphem dargestellt werden können.\\

Das Schwa wird im Armenischen zwar durch ein Graphen (arm.: {\artm u' }) in der Orthographie dargestellt, nichtsdestotrotz gibt es viele Wörter, deren orthographosche Schreibweise einen Cluset beinhaltet, der in der Auspracheform durch ein Schwa zu einer Silbe geformt wird. Beispiele hierfür :
\todo{Tabelle?}





\todo{Was ist uns biher über die Phonotaktik und Phonologie der Armenischen bekannt? H.Hovhannisyan, Vaux, Dum-Tragut.}


Der Mangel an Literatur zur armenischen Phonotaktik, sowie zu Phonologie und Phonetik der gesprochenen armenischen Sprache hat dazu geführt, dass die Legalität mancher Lautkombinationen nicht mit den Regeln der uns bekannten Literatur geprüft werden konnte. Daher sollten tatsächliche Wörter aus dem Armenischen gefunden werden, die die Lautfolgen der Pseudowörter enthalten. 


Alle Phoneme, die in einer Sprache vorkommen, werden im Phoneminventar der jeweiligen Sprache aufgeführt. Jedoch sind nicht alle Kombinationen dieser Laute legal. Da Hörer illegale Lautkombinationen als unnatürlich empfinden,  sollten diese in Stimulis nicht vorkommen.\\


Das armenische Phoneminventar unterscheidet sich vom deutschen, unter Anderem dadurch, dass es nur sechs Vokale hat. Dafür besitzt es stimmlose, stimmhafte sowie aspirierte Variationen der bilabialen, alveodentalen sowie velaren Konsonanten, die alle bedeutungsunterscheidend sind. \todo{weiter schreiben}



%\newcommand{\BlankCell}{}
\begin{figure}
	\caption{Konsonanten des Armenischen}
	\centering
	\begin{adjustbox}{width=1\textwidth}
	%\begin{center}
		\begin{tabular}{|l|ccc|cc|ccc|ccc|cc|ccc|cc|cc|}
			%\begin{tabular}{|l|cc|}
			\hline & 
			\multicolumn{3}{|c|}{\footnotesize{Bilabial}} &					% Bilabial
			\multicolumn{2}{|c|}{\footnotesize{Lab. dent.}} & 			% Labiodental
			\multicolumn{3}{|c|}{\footnotesize{Alveolar}} & 					% Alveolar
			\multicolumn{3}{|c|}{\footnotesize{P-alveo.}} & 				% Post-alveolar
			\multicolumn{2}{|c|}{\footnotesize{Palatal.}} & 		% Palatal
			\multicolumn{3}{|c|}{\footnotesize{Velar}} & 				% Velar
			\multicolumn{2}{|c|}{\footnotesize{Uvular}} & 					% Uvular
			\multicolumn{2}{|c|}{\footnotesize{Glottal}} \\					% Glottal			
			\hline Plosive &  							% Plosive
			p & p\super{h} & b &													% Bilabial
			&&														% Labiodental
			t & t\super{h} & d							% Alveolar
			% Post-alveolar
			&&&
			&&														% Palatal
			& k & k\super{h} & g 													% Velar
			&&										% Uvular
			&&										 % Glottal	
			 \\											
			\hline Nasal & 							% Nasal
			& m & &													% Bilabial
			& &											% Labiodental
			& n & &								%  Alveolar			
			% Post-alveolar
			& &	&													
			& & 														% Palatal
			& & &														% Velar
			& &														% Uvular
			 &		% Glottal
			 \\	 
			
			\hline Trill &  								% Trill
			& &	&										% Bilabial
			& &														% Labiodental
			&r&								% Alveolar
			&								% 
			% Post-alveolar
			& &	&													% Retroflex
			& &														% Palatal
		    & &		% Velar
			& &											% Uvular
			& &        \\		% Glottal			
			\hline Tap/Flap &  						% Tap /Flap
			& &													% Bilabial
			& &														% Labiodental			 					
			& & \ipa{R} &&					% Alveolar
			% Post-alveolar
			& &	&												
			& &														% Palatal
			& &	&	% Velar
			& &														% Uvular
			&   \\		% Glottal			
			\hline Fricative & 						% Fricative
			 & & &									% Bilabial
			f & v &													% Labiodental								% 
			s & & z &												% Alveolar
			\ipa{S} & & \ipa{Z} &									% Post-alveolar
			 & &								% Palatal
			& &	&							% Velar										% 
			\ipa{X} & \ipa{K} &									% Uvular
			 h &  \\										% Glottal			
			\hline 
			Affricate & 					% Africates
			&  & &		% Bilabial
			&  &		% Labiodental
			\texttslig &\texttslig{\super{h}}	&\textdzlig & % Alveolar		
			% Post-alveolar			
			\textteshlig & \textteshlig{\super{h}} & \textdyoghlig &
			& &														% Palatal
			& &	&													% Velar
			& &														% Uvular
			&         \\   % Glottal
			
			\hline Approx & 							% Approx.
			& &	&													% Bilabial
			& &											% Labiodental
			& & &								% Alveolar					
			% Post-alveolar
			&  & &											
			& j &													% Palatal
			& &	&								% Velar
			& &														% Uvular
			& 													% % Glottal
			\\		
			
			\hline Lat. appr. & 					% Lat. Approx
			& &	&	% Bilabial
			& &		% Labiodental
			&&l&								% Alveolar
			% Post-alveolar
			& &	&										
			& &												% Palatal
			& & &											% Velar
			& &														% Uvular
			& 	\\% Glottal
			\hline
		\end{tabular}
	%\end{center}
	\end{adjustbox}
\end{figure}


\begin{figure}
	\caption{\textbf{Vokalinventar des Armenischen}}\label{chart:vowel_chart}	

	\begin{center}
		{\Large
		\begin{vowel}				
			\putcvowel[l]{i}{1}		
			\putcvowel[l]{\textepsilon}{3}		
			\putcvowel[l]{\textscripta}{5}		
			\putcvowel[r]{\textopeno}{6}		
			\putcvowel[r]{u}{8}		
			\putcvowel{\textschwa}{11}	
		\end{vowel}
		}
	\end{center}

\end{figure}


Die oben beschriebenen Aspekte der armenischen Phonologie sollten bei der Wortauswahl berücksichtigt werden.

\subsection{Wortauswahl}
\label{sec:pseudowords}

\todo{2 Phasen: 1. wortauswahl,Manipulation 2. Wortauswahl = Stimuliauswahl}
Für die Auswahl der Wörter wurden folgende Ausschlusskriterien festgelegt, wobei die Kriterien eins bis vier bei der Vorauswahl eine Rolle spielten (Phase 1 ). Das Kriterium fünf hingegen kam erst bei der Nachbearbeitung zum
Einsatz (Phase 2).Pharyngeal


\begin{enumerate}
	\item Das Pseudowort enthält	mindestens ein Phonem, das im armenischen Phoneminventar nicht vorkommt.
	\item Das Pseudowort entspricht nicht der armenischen Phonotaktik, das heisst es beinhaltet mindestens eine
	illegale Lautkombination für die armenischen Hörer.
	\item Das Pseudowort beginnt mit einem Vokal.
	Da die Sprecher der Pseudowörter Deutsche sind, werden Wörter die mit einem Vokal beginnen
	mit einem stimmlosen glottalen Plosiv ausgesprochen, was bedeutet, dass der Onset der ersten Silbe ein stimmloser glottaler Plosiv ist. 
	Im Armenischen hingegen wird nicht unbedingt ein stimmloser glottaler Plosiv ausgesprochen, daher könnte dies von den Probanden als unnatürlich empfunden werden und deshalb wurden diese Wörter aussortiert.
	\item Die Aussprache des Pseudowortes zeigt auffällige Unterschiede, wenn es von verschiedenen Sprechern ausgesprochen wird. 
	\item Mindestens ein manipuliertes Sprachsignal des Pseudowortes entspricht nicht mehr den geforderten
	Qualitätsansprüchen an die Natürlichkeit, zum Beispiel weil es bei der Resynthese zu einer Artefaktbildung kam.	
\end{enumerate}


(\todo{Bild Beispiel mit Artefakten})
Caption: Bei manchen Sprachaufnahmen waren Artefakte nach der Resynthese zu hören. Diese Aufnahmen wurden aus der Stimuli-Liste herausgenommen.


Die verwendeten Pseudowörter sind hinsichtlich der Phonotaktik für die deutsche Sprache geprüft, was jedoch für Armenisch nicht gilt. Nicht alle Phoneme die im Deutschen vorkommen, kommen auch im Armenischen vor. Deswegen wurden die Wörter hinsichtlich der Phonotaktik des Armenischen geprüft und die Pseudowörter, welche für die armenische Sprache illegale Lautkombinationen enthalten, aus der Auswahlliste herausgenommen. 

\todo{einen Cluster finden, der für de legal ist, für am nicht}.

Die Schwierigkeit war dabei, dass es über die Phonotaktik der gesprochenen Sprache in Armenien nicht ausreichend Literatur gibt. Die geschriebene Sprache wurde zwar ausreichend analysiert, die
gesprochene Sprache dagegen nicht. \\

Da die verfügbare Information über die armenische Phonotaktik in der Literatur für diese Überprüfung nicht ausreichend war, basiert sie auf Beispielwörtern aus dem Armenischen, in denen die Lautkombinationen der Pseudowörter vorkommen.

Manche Autoren, die die armenische Phonotaktik dargestellt haben, stellen die orthographischen Regeln dar (\todo{Ajarian missing, andere Autoren für Phonetik missing, und die dum-targuto.ä. }).



{
	\renewcommand{\arraystretch}{1.2}
	\begin{table}[!t]
		\centering
		
		\caption{\textbf{Die folgenden Pseudowörter wurden als Stimuli ausgewählt.} Nach der Prüfung der Legalität für armenische Hörer, sowie der Qualitätsprüfung sind nur 4 Pseudowörter zur Auswahl geblieben.} \label{table:stimuli}
		
		\begin{tabular}{@{}lllll}
			
			\toprule
			
			\textbf{PSEUDOWORT} & \textbf{KAN} & \textbf{IPA} & \textbf{ARM IPA} & \textbf{ARM}\\
			
			\midrule
			
			tápik & ta:pIk & \textipa{[tAp\super{h}ik\super{h} ]} & \textipa{[tatik] [mArt\super{h}ik\super{h}]} & {\artm tatik, mardik } \\
			misuk & mizUk &	\textipa{[mizuk\super{h}]} & \textipa{[mitum] [bAzuk] [mORuk\super{h}]} & {\artm mijaket, bazuk, moruq } \\			
			sawet &	zav@t & \textipa{[zAvEt\super{h}]} & \textipa{[zAtik] [gEt\super{h}]} & {\artm Zaven, havet, geth } \\
			nemmok & nemOk & \textipa{[nEmOk\super{h}]} & \textipa{[nEmRut\super{h}] [kAnEm] [kuzEs]} & {\artm Nemruth, kanem, kuzes, kamoq} \\		
			
			
			
			\bottomrule
			
		\end{tabular}
		
	\end{table}
}



\subsection{Werkzeuge: eigene und bestehende}

Für das Experiment wurde die Percy Software benutzt \autocite{Draxler2011, Draxler2014}. 

\todo{text schreiben}
Praat
Python 
Parselmouth ist eine Schnittstelle zwischen Python und Praat. Durch Parselmouth können Praat befehle aus einem Python-Skript durchgeführt werden. Die Manipulation von Stimuli wurden mittels Parselmouth durchgeführt. 		 
Percy
Git


\subsection{Manipulation der Sprachsignale}

Die 48 Sprachsignale, die aus dem Magdeburger Prosodie-Korpus stammen, dienten als Grundlage für die Vorbereitung der Stimuli. Die Grundfrequenz wurde bei den Originalsprachaufnahmen erhöht. Anschließend wurde die Dauer der Originalsprachsignale verkürzt, um dadurch ein höheres Sprechtempo zu erzielen. Dadurch haben sich drei Klassen der Stimuli ergeben: Original, F0-manipuliert, Tempo-manipuliert (\autoref{table:design}). Auf diese Weise kann die Emotionswahrnehmung zwischen Armeniern und Deutschen verglichen werden. Ebenfalls kann untersucht werden, wie gut die Hörer die gespielten Emotionen erkennen können, wenn der Sprecher dieselbe oder nicht dieselbe Muttersprache hat wie sie. Außerdem können die die Auswirkungen der ausgewählten akustischen Merkmale auf die Emotionswahrnehmung bei jeder Kultur isoliert untersucht werden. 

\subsubsection{Manipulation der Grundfrequenz}
\label{sec:f0_manipulation}
Die Grundfrequenz steht im Verhältnis zur Vokalhöhe (\todo{cite!}Peterson and Barney, 1952; Ohala, 1937; Traunmüller, 1995).

Für die Manipulation der Sprachsignale wurde auf die Pythonbibliothek Parselmouth zugegriffen, die als
Schnittstelle zwischen Python und Praat den Zugriff auf die Praat-Funktionalität ermöglicht (\cite{Jadoul2018a}). Da die Datenvorbereitung für die Originalsprachsignale in einer Pythonumgebung durchgeführt wurde, war es sinnvoll, die Datenmanipulation ebenfalls in dieser Umgebung vorzunehmen.\\

\bigskip


\begin{figure}
	\centering
	\begin{subfigure}{1\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{pics/nemmok.png}
		\caption{original}
		\label{fig:nemmok_original}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{1\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{pics/nemmok_pitch.png}
		\caption{f0 manipuliert}
		\label{fig:nemmok_pitch}
	\end{subfigure}
	\caption{\textbf{Stimulusvergleich: f0 unverändert(a) und manipuliert(b) .} Oszillogramm(oben) und Spektrogramm (unten) für das Pseudowort \emph{nemmok} (IPA: \textipa{[nEmOk\super{h}]}). Prosodischer Ausdruck neutral augesprochen mit Frauenstimme. Die blaue Linie auf dem Spekrogramm zeigt den Verlauf der Grundfrequenz. Die Grundfrequenzwerte im gesamten Originalsprachsignal (a) wurden um 8 Halbtöne erhöht (b). }
	\label{fig:f0_manipulation}
	
	
\end{figure}
	
\begin{tcolorbox}
	
	Exkurs : Grundfrequenz (F0)
	
	Die Frequenzen der gesprochenen Sprache eines Menschen sind immer ein Vielfaches der jeweiligen Grundfrequenz.
	Jeder Mensch verfügt über ein Spektrum von Grundfrequenzen, welches sich im Laufe des Lebens ändert. So bestehen Unterschiede der F0-Bereiche sowohl zwischen Geschlechtern als auch zwischen Kindern und Erwachsenen.
	
	Die Grundfrequenz entsteht durch die Anspannung der Stimmlippen, welche beim Sprechen durch das Heben und Senken des Kehlkopfes beeinflusst wird. Angespannte Stimmlippen erzeugen höhere Grundfrequenzen in einem kontinuierlichen Spektrum. So ist die intrinsische Grundfrequenz eines Sprechers bei dem vorderen geschlossen ungerundeten Vokal [i] höher als bei dem vorderen halboffenen ungerundeten Vokal [e].

\end{tcolorbox}

\bigskip

\noindent
Die Änderung der Grundfrequenz wurde nur in eine Richtung durchgeführt - sie wurde erhöht. Aus der entgegengesetzten Perspektive kann die künstliche Erhöhung der Grundfrequenz zu einer
Änderung in der Vokalqualität führen. Für die Vokalqualität ist zudem die tonotopische Distanz von Bedeutung, wie z.b. die Distanz zwischen F0 und F1. Um zu verhindern, dass bei einer Erhöhung der Grundfrequenz die Vokalqualität leidet, wurde die Manipulation der Originalsprachsignale in zwei Phasen durchgeführt:

\begin{enumerate}
\item Systematische Manipulation der Originalsprachaufnahmen um 2-9 Halbtöne.
\item Hörprüfung und Auswahl der Halbtonstufe, damit die höchste Änderung in der Emotionswahrnehmung erreicht wird, ohne dass die Vokalqualität und Natürlichkeit beeinträchtigt wird.
\end{enumerate}



Als Einheit für die Grundfrequenzerhöhung wurde der Halbton benutzt, damit die Natürlichkeit der Harmonischen bewahrt bleibt, d.h.damit die Stimme natürlich klingt. Die Grundfrequenz bei den Originalsprachaufnahmen wurde in der Phase 1 stufenweise jeweils um 2, 3, 4, 5, 6, 7, 8 und 9 Halbtöne erhöht. Anschließend wurden die manipulierten Sprachsignale mit den originalen Sprachaufnahmen verglichen. Dadurch konnte festgestellt werden, ob die Änderung der Grundfrequenz durch das menschliche Gehör wahrgenommen werden kann. Dies wurde durch persönliche Hörproben evaluiert. \todo{Es wird vermutet, dass die Änderung unter 5 Halbtönen nicht als Änderung wahrgenommen kann ???? REFERENZ FINDEN DRINGEND! Burkhardt? oder Zitat bei Burkhardt? sonst 'pitch shift emotion perception' suchen}\\

Es wird vermutet, dass eine Pitch-Änderung um weniger als 4 Halbtöne keinen großen perzeptiven Unterschied macht \autocite{Ye2020}. Auf Grund dieser Vermutung wurde die Manipulation für diese Arbeit unter vier Halbtönen nicht weiter in Betracht gezogen. \\



\todo{ab hier mit dem oberen Text vergleichen, anpassen}



Die Erhöhung der Grundfrequenz erfolgte nicht nur bei einzelnen Vokalen, sondern die F0-Ebene wurde extrahiert und alle Grundfrequenzwerte im Sprachsignal wurden gleichermaßen erhöht. So wurde der komplette Grundfrequenzverlauf des Sprachsignals erhöht.\\


Bei der anschließenden Hörprüfung (Phase 2) hat sich herausgestellt, dass bei Sprachsignalen, deren F0 um 9 Halbtöne erhöht wurden, eine Änderung der Vokalqualität zu hören war. Damit hat sich die Erhöhung um 8 Halbtöne als zielführend erwiesen.\\

Als weiteres Kriterium für die Auswahl der manipulierten Sprachsignale wurde die Signalqualität herangezogen. Diese sollte nicht beeinträchtigt werden. Dabei erwies sich eine creaky voice als Ausschlusskriterium. Bei den Originalsprachsignalen, welche mit creaky voice produziert wurden, sind nach der Resynthese der Sprachsignale, Artefakte entstanden, wodurch die Sprecherstimmen nicht mehr natürlich klangen.

\subsubsection{Manipulation des Sprachtempos}
\label{sec:tempo}

Die Dauer wurde zunächst stufenweise um Faktor 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8 und 0.9 skaliert. Anschließend wurde Faktor 0.65 ausgewählt, da die Sprachsignale einen Unterschied zum Originalaufnahmen aufweisen.

Parameter "Scale times by":
Factor: 0.65

Verkürzung der Dauer um Faktor 0.65 heisst 35 Prozent schneller.


\begin{figure}
	\centering
	\begin{subfigure}{1\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{pics/nemmok.png}
		\caption{original}
		\label{fig:nemmok_original}
	\end{subfigure}
	\par\bigskip  
	\begin{subfigure}{1\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{pics/nemmok_tempo.png}
		\caption{Dauer manipuliert}
		\label{fig:nemmok_tempo}
	\end{subfigure}
	\caption{\textbf{Stimulusvergleich: Dauer unverändert(a) und manipuliert(b) .} Oszillogramm(oben) und Spektrogramm (unten) für das Pseudowort \emph{nemmok} (IPA: \textipa{[nEmOk\super{h}]}). Prosodischer Ausdruck neutral augesprochen mit Frauenstimme. Die Dauer des Originalsprachsignals beträgt ~0.96 s. (a), nach der Manipulation der Dauer um Faktor 0.65 beträgt die Dauer des Sprachsignals (b) ~0.62 s. Dies entspricht einer Erhöhung der Sprechgeschwindigkeit um 35\%. Die blaue Linie auf dem Spekrogramm zeigt den Verlauf der Grundfrequenz. Bei der Manipulation der Dauer ist die Grundfrequenz gleich geblieben.}
	\label{fig:tempo_manipulation}
\end{figure}


\todo{ab hier mit dem oberen Text vergleichen, anpassen}

Für die Manipulation des Sprachtempos wurde wiederum die Parcelmouthbibliothek verwendet, um Praat-Befehle auszuführen.
Praat benutzt den PSOLA (Pitch-synchronous overlap-and-add) \autocite{Charpentier1989}, der für die Dauermanipulations der Sprachsignale eingesetzt wurde. Der Algorithmus unterteilt die Sprachsignale in kleine Segmente. Diese werden dann überlappend übereinanderrgesetzt, um die Dauer des Signals zu verkürzen. Dabei sollte beachtet werden, dass wenn PSOLA uas das Sprachsignal direkt angewendet wird, wird die Grundfrequenz ebenfalls manipuliert. Daher sollte bei der Tempomanipulation zunächst die Dauerebene extrahiert werden und anschließend PSOLA-Algorithmus lediglich auf die Dauerebene angewendet werden. Dadurch bleien alle anderen Merkmale des Sprachsignals, inklusive F0, unverändert.
In dieser Arbeit wurde der Psolar-Algorythmus nicht nur auf die Vokale, sondern auf das komplette Sprachsignal angewendet.\\

Dabei war es wichtig, zu beachten, zunächst die Dauerebene des Signals zu extrahieren, sie dann zu verkürzen und anschließend Dauerebene und Sprachsignal zu resyntetisieren, um zu verhindern dass sich die Grundfrequenz durch die Verkürzung der Dauer des Sprachsignals erhöht.\\

Die Manipulation des Sprachtempos wurde ebenfalls stufenweise durchgeführt. Die Dauer wurde um die Faktoren 0,3-0,8 (?)verkürzt.
Die optimale Stufe bedeutet eine hörbare Änderung im Vergleich zum Origanalsignal bei Beibehaltung der Natürlichkeit.
Als bester Faktor stellte sich der Faktor 0,65 heraus.
Eine Verkürzung des Sprachignals um den Faktor 0,65 entspricht einer Erhöhung der Sprachgeschwindigkeit um 35\%




\subsection{Experimentdesign}
\label{sec:experiment_design}

Das Experiment wurde als eine explanative Feldstudie durchgeführt. 
\newline


Die verfügbaren Stimuli 

{
	\renewcommand{\arraystretch}{1.2}
	\begin{table}[!t]
		\centering
		
		\caption{\textbf{Nach der Manipulation der Sprachsignale hat sich für jedes Experiment folgendes Bild ergeben:}} \label{table:design}
		
		\begin{tabular}{ | c | c | c | c |}
			
			\toprule
			
			\textbf{Original} & \textbf{F0} & \textbf{Tempo}\\
			
			\midrule
			
			\makecell{2 Sprecher \\**\\ 4 Wörter \\**\\ 6 prosodische Ausdrücke} & 
			\makecell{2 Sprecher \\**\\ 4 Wörter \\**\\ 6 prosodische Ausdrücke} & 
			\makecell{2 Sprecher \\**\\ 4 Wörter \\**\\ 6 prosodische Ausdrücke}\\
			
			\midrule
			
			48 Sprachsignale & 48 Sprachsignale & 48 Sprachsignale \\	
			
			\hline
			
			\multicolumn{3}{| c |}{\textbf{insgesamt 144 Stimuli}} \\
			
			\bottomrule	
			
					
			
		\end{tabular}
		
	\end{table}
}

Mit Hilfe der Schneeball-Methode wurde der Link zu diesem Web-Experiment verbreitet. 
Für die Qualitätsprüfung der Annotationen wurde eine Kontrollfrage eingebaut.
Die Kontrollfrage sollte dazu dienen, die Annotationen der Teilnehmer, die nicht Aufmerksam waren und zufällige Emotionen für die Stimuli gewählt haben, aus der weiteren Datenanalyse auszuschließen. Ein Audioaufnahme mit Applaus wurde als Stimulus für die Kontrollfrage benutzt. Dazu sollten die Teilnehmer die Option 'Klatschen' anstatt einer Emotion wählen. Es wurden nur die Annotationen der Höher analysiert, die die Kontrollfrage richtig beantwortet haben. Außerdem wurden die Daten für jeden Teilnehmer hinsichtlich folgender Kriterien geprüft: 

\begin{itemize}
	\item Muttersprache der Teilnehmer des deutschen Experimentes ist Deutsch 
	\item Muttersprache der Teilnehmer des armenischen Experimentes ist Armenisch
	\item Deutsch kommt in der Liste der angegebenen Fremdsprachen nicht vor
	\item Armenisch kommt in der Liste der angegebenen Fremdsprachen nicht vor
	\item es sind 151 Einträge für den Teilnehmer vorhanden, dabei versteht es sich folgendes:
	
	\begin{itemize}	 
		\item Annotationen für alle Stimuli (insgesamt 144 Sprachaufnahmen und eine Kontrollfrage) sind vorhanden
		\item alle Persönlichkeitsfragen (insgesamt fünf Fragen) wurden beantwortet
		\item die Frage nach der Natürlichkeit der Stimme von den Sprechern wurde beantwortet
	\end{itemize}
\end{itemize}



Das Experiment sollte möglichst erreichbar für die Teilnehemer der beiden zu vergleichenden Länder sein. Außerdem sollten in eher kuzer Zeit möglichst viele Personen an dem Experiment teilnehmen. Für diese Ziele hat sich ein Web-Experiment sehr gut geignet, das die Erreichbarkeit für ein solches Experiment höher ist, als für ein Laborexperiment, bei dem die Teilnehmer persönlich und wahrscheinlich einzeln eintreten müssten. Daher wurde es entschieden, dass sich ein Web-Experiment am besten für die aktuelle Studie eignet. 

Die verfügbaren Platformen, die benutzt werden konnten, um ein online Experiment durchzuführen, wurden  zunächst verglichen. Percy Software \parencite{Draxler2011} 


\subsection{Hörtest und Fragebogen}
\label{sec:stimulusobject}


Datenschutz: anonym
Meta Daten


Die Teilnehmer hatten die Aufgabe alle Stimuli zu kategorisieren, indem sie für jedes Sprachsignal eine Emotion wählen. 
\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{pics/experiment/experiment_active_buttons.png}
	\caption{\textbf{Diskriminationsaufgabe.} Die Frage zur Kategorisierung des Stimulus zu einer Emotion. }
	\label{fig:experiment_question}
\end{figure}


 Der Stimulus konnte mit dem Kopfhörersymbol abgespielt werden. Für alle Stimuli wurde den Teilnehmern die selbe Frage gestellt. Für die Aktivierung der Auswahloptionen musste der Stimulus mindestens einmal abgespielt werden. Die Teilnehmer durften jede Sprachaufnahme maximal dreimal hören. Sobald der Teilnehmer eine der unter der Frage dargestellten Optionen ausgewählt hat, wurde der nächste Stimulus präsntiert. Es konnte nur eine der angegebenen Optionen ausgewählt werden.
 
\subsubsection{Fragen zur Persönlichkeit}

hier können ein paar graphiken noch rein, die die Emotionswahrnehmung abhängig von dem Persönlichkeitstyp darstellen.

\subsubsection{Kontrollfrage}
Qualitätskontrolle für die Aufmerksamkeit der Höher. Bei dem Experiment sollte 'Klatschen' statt einer Emotion ausgewählt werden, wenn der Stimulus Applaus-Geräusche statt menschlicher Sprache war. Außerdem wurde kontrolliert, ob der Teilnehmer die Option 'Klatschen' für einen Stimulus mit einem prosodischen Ausdruck gewählt hat. In diesem Fall wurden die Daten der Teilnehmer aus der weiteren Datenanalyse herausgenommen.

\subsection{Probandenauswahl a posteriori}

{
	\renewcommand{\arraystretch}{1.2}
	\begin{table}[!t]
		\centering
		
		\caption{\textbf{Vergleich der Teilnahmen der deutschen und der armenischen Probanden.}\\
		Experiment: das Experiment für die jeweilige Sprache\\
		Tailnahmen: Anzahl der Probanden, die teilgenommen haben\\
		vollständig: Anzahl der Probanden, die das Experiment erfolgreich beendet haben\\
		verwertbar: Anzahl der Probanden, deren Eingaben die Bedingungen des Experiments erfüllt haben. Nur diese Daten konnten analysiert werden.} \label{table:participants}
		
		\begin{tabular}{@{}llll}
			
			\toprule			
			\textbf{Experiment} & \textbf{Teilnahmen} & \textbf{vollständig} & \textbf{verwertbar}\\			
			\midrule			
			 Deutsch & 41 & 29 & 21\\						
			 Armenisch & 57 & 28 & 13\\				
			\bottomrule				
			
		\end{tabular}
		
	\end{table}
}


 
\chapter{Datenanalyse}

Ab hier werden die Annotationen der Probanden analysiert. Zunächst werden die Teilnehmerdaten beschrieben. Anschließend werden die Ergebnisse der Annotationen für die armenische sowie für die deutsche Version des Experimentes dargestellt und interpretiert.

\section{Demographische Auswertung der Teilnehmerdaten}

wie viele Männer/Frauen haben bei jedem experiment teilgenommen? 
Durschnittsalter und Standardabweichung


{
	\renewcommand{\arraystretch}{1.2}
	\begin{table}[!t]
		\centering
		
		\caption{\textbf{Anzahl und Alter der Teilnehmer.}} \label{table:participants_age}
		
		\begin{tabular}{ |p{2cm}||p{1cm}|p{1cm}|p{2cm}||p{1cm}||p{1cm}|p{1cm}|p{1cm}| }
			
			\toprule
			
			\multirow{2}{*}{\textbf{Kultur}} & \multicolumn{3}{|c||}{\makecell{\textbf{Anzahl} \\ \textbf{nach Geschlecht}}} & \multicolumn{4}{|c|}{\textbf{Alter}} \\
			
			\hline
			
			 &\textbf{m} & \textbf{f} & \textbf{gesamt }  &  \textbf{mean} & \textbf{min} & \textbf{max} & \textbf{SD} \\
			
			\midrule
			
			Deutsch & 9 & 12 & 21& 43.5 & 20 & 73 & 18.1 \\
			\hline
			Armenisch & 4 & 9 & 13  & 26.2 & 18 & 43 & 8.4\\	
			
			\bottomrule
		\end{tabular}
		
	\end{table}
}






\bigskip


\begin{figure}
	\centering
	\begin{subfigure}{1\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{plots/ewe_de.png}
		\caption{Deutsche Teilnehmer}
		\label{fig:ewe_de}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{1\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{plots/ewe_am.png}
		\caption{Armenische Teilnehmer}
		\label{fig:ewe_am}
	\end{subfigure}
	\caption{\textbf{Interrater-Reliabilität der deutschen (a) und der armenischen (b) Teilnehmer.} Der Korrelationskoeffizient \emph{r} (y-Achse) für jeden Teilnehmer (x-Achse) berechnet durch die Korrelation (Pearson) zwischen meistgewählten Antworten für jeden Stimuli  und den Antworten des Teilnehmers.}
	\label{fig:ewe}
	
	
\end{figure}



\section{Vergleich der eigenen Daten mit der Evaluation des Magdeburger Prosodie-Korpus}

nur die Bewertungen von den deutschen Hörern für die Originalaufnahmen.
Die Originalsprachaufnahmen, die als Stimuli in diesem Experiment vorkommen, wurden bei Erstellung des Magdeburger Prosodie-Korpus bereits validiert . Die Validierung der Daten wurden durch Hörtests mit deutschen Hörern durchgeführt. Im Rahmen dieser Arbeit haben die Hörer Originalsprachaufnahmen, sowie deren Manipulationen bewertet. Für den Vergleich der Ergebnisse dieser Studie mit der Evaluation des Magdeburger Prosodie-Korpus wurden lediglich die Annotationen der Originalsprachsignale analysiert. 

\citeauthor{Wendt2002} berichtet über die geringe Akzeptanz der Hörer bei dem prosodischen Ausdruck für Trauer \autocite{Wendt2002}. In \autoref{fig:wasep_evaluation} wird folgendes ersichtlich: es gibt einen auffälligen Unterschied bei Bewertungen der Emotion Trauer zwischen Männerstimme und Frauenstimme. 
Hohe Schwankungsbreite in Ergebnissen, das kann daran liegen, da nur 4 Pseudowörter vs 200 im Sprachkorpus. 

\begin{figure}[t!] % "[t!]" placement specifier just for this example
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_F_Trauer.png}
		\caption{Bewertungen der deutschen Hörer für Frauenstimme} \label{fig:de_f_T}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_F_Trauer.png}
		\caption{Bewertungen der armenischen Hörer für Frauenstimme} \label{fig:am_f_T}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_M_Trauer.png}
		\caption{Bewertungen der deutschen Hörer für Männerstimme} \label{fig:de_m_T}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_M_Trauer.png}
		\caption{Bewertungen der armenischen Hörer für Männerstimme} \label{fig:am_m_T}
	\end{subfigure}
	
	\caption{Die Emotionswahrnehmung für die prosodischen Äußerung Trauer für Männer- und Frauenstimme bei deutschen (links) und armenischen (rechts) Hörer.} \label{fig:speaker_tone_T}
\end{figure}



\todo{Durschnitttrefferquote für alle Emotionen ausrechnen.}

\section{Vergleich der Emotionswahrnehmung von armenischen und deutschen Hörern}

\begin{figure}[t!] % "[t!]" placement specifier just for this example
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/heatmap/conf_original_de.png}
		\caption{Annotationen der deutschen Hörer für Originalsprachsignalen} \label{fig:conf_original_de}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/heatmap/conf_original_am.png}
		\caption{Annotationen der armenischen Hörer für Originalsprachsignalen} \label{fig:conf_original_de}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/heatmap/conf_pitch_de.png}
		\caption{Annotationen der deutsche Hörer für F0-Manipulation} \label{fig:conf_pitch_de}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/heatmap/conf_pitch_am.png}
		\caption{Annotationen der armenischen Hörer für F0-Manipulation} \label{fig:conf_pitch_am}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/heatmap/conf_tempo_de.png}
		\caption{Annotationen der armenischen Hörer für Tempo-Manipulation} \label{fig:conf_tempo_de}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/heatmap/conf_tempo_am.png}
		\caption{Annotationen der armenischen Hörer für Tempo-Manipulation} \label{fig:conf_tempo_am}
	\end{subfigure}
	
	\caption{My complicated figure} \label{fig:confusion_heatmap}
\end{figure}



\subsection{Intrakulturelle Unterschiede, Persönlichkeitsunterschied}

Wie werden die unterschiedlichen Emotionen von Deutschen und Armeniern identifiziert?
Folgende sechs Diagramme der einzelnen Emotionen zeigen in der linken Spalte die Wahrnehmungen Original, manipulierte f0 und manipuliertes Tempo der deutschen und in der Rechten die der armenischen Teilnehmer. So können sowohl beiden untersuchten Kulturen als auch der Einfluss der einzelnen Merkmalsvariationen auf die Emotionswahrnehmung verglichen werden.

\subsection{Freude}
\label{sec:Freude}

\emph{Originalaufnahmen} (\autoref{fig:de_F} und \ref{fig:am_F}) \\ 

Es fällt auf, dass Freude bei beiden Kulturen häufig mit der Emotion Neutral verwechselt wird. Während die Deutschen in etwas mehr als der Hälfte der Fälle mit 54.8\% die Sprachaufnahme als Freude identifizieren, tun dies bei den Armeniern mit 34,6\% knapp über ein Drittel der Teilnehmer. 49\% der Armenier nehmen das Sprachsignal Freude als neutral wahr.
Der Unterschied zwischen den Kulturen, der statistisch signifikant ist (p<0.05), lässt sich mit der unter Punkt 3.1 erwähnten Vermutung, dass Menschen, deren Muttersprache mit der Sprache des Sprechers übereinstimmt, die Emotionen besser zuordnen können, erklären.
Zudem werden die zu erwartenden Zuordnungen zu neutral auch auf die anderen vier Emotionen verteilt.\\

\noindent
\emph{Grundfrequenzmanipulation} (\autoref{fig:de_F_F0} und \ref{fig:am_F_tempo}) \\
Sehr signifikant zwischen DE und AM (p<0.001)
Hier kann man erkennen, dass mit der Erhöhung der Grundfrequenz eine Steigerung der Zuordnung zur Emotion Freude erfolgt. Dieser Zuwachs fällt bei deutschen und Armeniern ähnlich aus.
Es könnte ein Zusammenhang bestehen mit der Tatsache, dass hohe Grundfrequenz ein akustischer Cue für den prosodischen Ausdruck Freude wahrgenommen wird. \\

\noindent
\emph{Tempomanipulation} (\autoref{fig:de_F_tempo} und \ref{fig:am_F_F0}) \\
(p<0.05)
Eine Erhöhung des Sprachtempos führt zu einer Zunahme der Einordnung als neutral. So haben über 60\% der Armenier das Signal als neutral wahrgenommen.
Dies kann man dadurch erklären, dass bei Freude die Vokaldauer länger ist.Das führt zur Verlangsamung des Sprachtempos.
Weiterhin sieht man, dass der Anteil der Interpretationen bei einer Erhöhung des Sprachtempos als Wut zunimmt.
Eine Erklärung hierfür könnte sein, dass hohes Tempo mit Wut assoziiert wird, weil deren prosodische Ausdrucksweise oft einen charakteristischen erhöhten  Sprechrythmus aufweist. 



\begin{figure}[t!] % "[t!]" placement specifier just for this example
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Freude.png}
		\caption{First subfigure} \label{fig:de_F}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Freude.png}
		\caption{Second subfigure} \label{fig:am_F}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Freude_F0.png}
		\caption{Third subfigure} \label{fig:de_F_F0}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Freude_F0.png}
		\caption{Fourth subfigure} \label{fig:am_F_F0}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Freude_tempo.png}
		\caption{Fifth subfigure} \label{fig:de_F_tempo}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Freude_tempo.png}
		\caption{Sixth subfigure} \label{fig:am_F_tempo}
	\end{subfigure}
	
	\caption{My complicated figure} \label{fig:countplots_F}
\end{figure}

\subsection{Trauer}
\label{sec:Trauer}

\emph{Originalaufnahmen} (\autoref{fig:de_T} und \ref{fig:am_T}) \\
Es konnte einen signifikanten kulturabhängigen Unterschied(p<0.05) in der Emotionswahrnehmung zwischen der beiden Kulturen für die originalen Sprachaufnahmen mit dem prosodischen Ausdruck Trauer festgestellt werden.
Die Emotion Trauer wurde zwar von den Hörern beider Kulturen besser identifiziert werden als der prosodischer Ausdruck Freude, aber es fällt auf, dass mehr armenische Hörer die Sprecher als verängstigt und neutral wahrgenommen haben, als die Teilnehmer des deutschen Experiments.\\

\noindent
\emph{Grundfrequenzmanipulation} (\autoref{fig:de_T_F0} und \ref{fig:am_T_F0}) \\
Statistisch sehr signifikanter Unterschied (p<0.001) zwischen Annotationen der armenischen und der deutschen Hörer.
Die Erhöhung der Grundfrequenzwerte hat keinen Einfluss auf die Wahrnehmung der Emotion Trauer bei den Deutschen gezeigt. Bei mannchen armenischen Hörern wurde die Pitch-Erhöhung mit Angst assoziiert, da 
21.2\% der armenischen höher haben die Stimme der Sprecher als ängstlich interpretiert. Die Erhöhung der Grundfreuqenz hat dazu geführt, dass die Stimmen zugunsten der Emotion Angst um 7.7\% gestiegen sind, dafür sinkt  die Kategorisierung der Stimuli als neutral.\\

\noindent
\emph{Tempomanipulation} (\autoref{fig:de_T_tempo} und \ref{fig:am_T_tempo}) \\

Trauer wird of mit durch einen langsamen Sprechrhythmus charakterisiert. Daher war es zu erwarten, dass die Sprechtempoerhöhung dazu beiträgt, dass die Accuracy bei traurigen prosodischen Äußerungen abnimmt, was hier gezeigt werden konnte (siehe \ref{fig:de_T_tempo} und \ref{fig:am_T_tempo}). Es ist auffällig, dass die Erhöhung des Sprechrythmus unabhängig von der Kultur dazu führt, dass die Wahrnehmung der Sprecherstimmen als neutral steigt. 

\begin{figure}[t!] % "[t!]" placement specifier just for this example
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Trauer.png}
		\caption{First subfigure} \label{fig:de_T}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Trauer.png}
		\caption{Second subfigure} \label{fig:am_T}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Trauer_F0.png}
		\caption{Third subfigure} \label{fig:de_T_F0}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Trauer_F0.png}
		\caption{Fourth subfigure} \label{fig:am_T_F0}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Trauer_tempo.png}
		\caption{Fifth subfigure} \label{fig:de_T_tempo}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Trauer_tempo.png}
		\caption{Sixth subfigure} \label{fig:am_T_tempo}
	\end{subfigure}
	
	\caption{My complicated figure} \label{fig:countplots_T}
\end{figure}


\subsection{Neutral}
\label{sec:neutral}

\emph{Originalaufnahmen} (\autoref{fig:de_s} und \ref{fig:am_s}) \\

Die Neutralität der Sprecherstimmen konnten von den Hörern der zu vergleichenden Kulturen mit einer Genauigkeit von über 75\% identifiziert werden. Dabei wurde Trauer von armenischen und deutschen Teilnehmern ähnlich oft mit der Emotion Wut verwechselt.\\

\noindent
\emph{Grundfrequenzmanipulation} (\autoref{fig:de_s_F0} und \ref{fig:am_s_F0}) \\

Die Trefferquote für neutral sinkt für die Stimuli mit einer erhöhten Grundfrequenz. Es ist auffällig, dass Grundfrequenzerhöhung bei beiden Kulturen zu einer Erhöhung der Einordnung der Stimuli als Freude um knapp 10\% führt, allerdings erhöhte Grundfrequenz hat bei den Armeniern dazu geführt, dass die Einordnung der Stimuli als Trauer um 16.4\% gestiegen ist. \\

\noindent
\emph{Tempomanipulation} (\autoref{fig:de_s_tempo} und \ref{fig:am_s_tempo}) \\
(p<0.05)
Bei beiden Kulturen ist zwar ein Einstieg für Wut zu sehen, allerdings die Mehrheit sowohl der armenischen als auch der deutschen Hörer konnten die Stimuli mit erhöhtem Sprechtempo als neutral identifizieren. Der Anstieg zugunsten der Emotion Wut kann dadurch erklärt werden, dass Wut oft mit einem schnellen Sprechrhythmus charakterisiert wird. Nichtsdestotrotz konnte die Mehrheit den prosodischen Ausdruck richtig identifizieren, was damit zusammen hängen könnte, dass Sprachtempo nicht nur als akustischer Cue für die Emotionswahrnehmung dient, sondern auch als sprecherspezifisches Merkmal wahrgenommen wird, da manche schneller sprechen , als andere. 


\begin{figure}[t!] % "[t!]" placement specifier just for this example
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_neutral.png}
		\caption{First subfigure} \label{fig:de_s}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_neutral.png}
		\caption{Second subfigure} \label{fig:am_s}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_neutral_F0.png}
		\caption{Third subfigure} \label{fig:de_s_F0}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_neutral_F0.png}
		\caption{Fourth subfigure} \label{fig:am_s_F0}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_neutral_tempo.png}
		\caption{Fifth subfigure} \label{fig:de_s_tempo}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_neutral_tempo.png}
		\caption{Sixth subfigure} \label{fig:am_s_tempo}
	\end{subfigure}
	
	\caption{My complicated figure} \label{fig:countplots}
\end{figure}


\subsection{Ekel}
\label{sec:Ekel}

\emph{Originalaufnahmen} (\autoref{fig:de_E} und \ref{fig:am_E}) \\
Ekel wurde bei beiden Kulturen am meisten mit anderen Emotionen verwechselt. Dazu weisen \citeauthor{Banse1996} darauf hin, dass die verbalen Äußerungen für Ekel eher spontan und weniger kontrolliert produziert werden \autocite{Banse1996}. Außerdem existieren bestimmte semantische Äußerungen, durch die die Emotion Ekel in einer Sprache ausgedrückt werden kann.  Dabei wird der prosodische Ausdruck für Ekel am Häufigsten mit Wut verwechselt. Die armenischen Hörer konnten Ekel in Originalaufnahmen minimal besser identifizieren, als die deutschen Hörer. 


\noindent
\emph{Grundfrequenzmanipulation} (\autoref{fig:de_E_F0} und \ref{fig:am_E_F0}) \\
Hier fällt es auf, dass die Grundfrequenzerhöhung bei der Emotion Ekel zu einer Wharnehmungsverschiebung in Richtung Angst vor allem bei den armenischen Hörern die. Bei den Deutschen ist eine Verdoppelung von 2.4\% auf 4.8\% zu beobachten, wobei bei den Armeniern fast eine Verdreifachung von 2.9\% auf 8.7\% zu sehen ist.


\noindent
\emph{Tempomanipulation} (\autoref{fig:de_E_tempo} und \ref{fig:am_E_tempo}) \\
Die prosodische Äußerung für Ekel mit einem erhöhten Sprechtempo wird bei beiden Kulturen gleichermaßen als Wut und Ekel wahrgenommen. Diese Verwechslung kann dadurch erklärt werden, dass Ekel und Wut negative Emotionen sind, wobei ein hoher Sprechrhythmus ist eher für die Emotion Wut charakteristisch ist. Daher wird die Sprecherstimme bei Tempomanipulation öfter als wütend wahrgenommen, als bei den Originalsprachsignalen. 

Zudem weisen die Signale der weiblichen Sprecherin eine sehr hohe Bandbreite auf, was eine Einordnung schwieriger machen kann (\autoref{fig:speaker_f0}).



\begin{figure}[t!] % "[t!]" placement specifier just for this example
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Ekel.png}
		\caption{First subfigure} \label{fig:de_E}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Ekel.png}
		\caption{Second subfigure} \label{fig:am_E}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Ekel_F0.png}
		\caption{Third subfigure} \label{fig:de_E_F0}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Ekel_F0.png}
		\caption{Fourth subfigure} \label{fig:am_E_F0}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Ekel_tempo.png}
		\caption{Fifth subfigure} \label{fig:de_E_tempo}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Ekel_tempo.png}
		\caption{Sixth subfigure} \label{fig:am_E_tempo}
	\end{subfigure}
	
	\caption{My complicated figure} \label{fig:countplots_E}
\end{figure}


\subsection{Angst}
\label{sec:Angst}

\emph{Originalaufnahmen} (\autoref{fig:de_A} und \ref{fig:am_A}) \\
Mehr als die Hälfte aller Teilnehmer identifizieren Angst als Angst (Deutsche 58,9\%, Armenier 59,6\%) . Ein grosser Anteil der falschen Zuordnungen entfällt hier auf die Emotion Trauer. Ein Viertel der Armenier und knapp ein Fünftel der Deutschen entscheiden sich fuer diese Antwort. Während bei den Armeniern die Zuordnungen des Signals zu Freude zu vernachlässigen sind, entscheiden sich bei den Deutschen immerhin knapp 7\% der Teilnehmer für diese Emotion. 


\noindent
\emph{Grundfrequenzmanipulation} (\autoref{fig:de_A_F0} und \ref{fig:am_A_F0}) \\
Sehr signifikant zwischen DE und AM (p<0.001)
Hier gibt es bei den Deutschen eine deutliche Steigerung der richtigen Zuordnungen um knapp 15\%. Die Antworten Trauer und neutral reduzieren sich um jeweils ungefähr die Hälfte, während der Anteil der Zuordnungen zu Freude fast identisch bleibt. Dies ist sehr interessant, da man sieht, dass sich bei der Manipulation  f0 der Freude die Zuordnungen zu Angst erhöhen \todo{Steffi um Erklärung des letzten  Satzes bitten}.\\
\noindent
Bei den Armeniern hingegen bleiben die richtigen Zuordnungen annähernd gleich. Hier verschieben sich die Antworten vor Allem von neutral Richtung Ekel.
Auch hier sieht man einen Zusammenhang mit der Erhöhung f0 bei der Emotion Ekel. Diese führt dort zu einer Steigerung der Zuordnungen zu Ekel.

\noindent
\emph{Tempomanipulation} (\autoref{fig:de_A_tempo} und \ref{fig:am_A_tempo}) \\
(p<0.05)
Bei der Erhöhung des Tempos gibt es bei den deutschen eine fast ebenso deutliche Steigerung der erwarteten Zuordnung wie bei dem ehöhten Grundfrequenzverlauf der Sprecherstimmen. Bei den Armenier hat dies kaum Auswirkung auf die Anzahl der Zuordnungen zu Angst.

Ebenso wie bei der Manipulation f0 gibt es einen deutlichen Unterschied zwischen den beiden Kulturen.
Bei den Armeniern bleiben die Zuordnungen sowohl zu Angst als auch zu neutral annähernd gleich. Die Sprecherstimmen werden als weniger traurig wahrgenommen, dafür erhöhen sich die Zuordnungen zu Freude und Wut.

Warum? Deutsche Angst assoziieren Angst stärker mit schnellerem und aufgeregterem Sprechen, während Armenier diese mehr mit mittlerem Tempo in Zusammenhang bringen. Dies zeigt sich auch bei den Originalaufnahmen Trauer, bei denen sich Armenier häufiger für die Emotion Angst entschieden haben.



\begin{figure}[t!] % "[t!]" placement specifier just for this example
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Angst.png}
		\caption{First subfigure} \label{fig:de_A}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Angst.png}
		\caption{Second subfigure} \label{fig:am_A}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Angst_F0.png}
		\caption{Third subfigure} \label{fig:de_A_F0}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Angst_F0.png}
		\caption{Fourth subfigure} \label{fig:am_A_F0}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Angst_tempo.png}
		\caption{Fifth subfigure} \label{fig:de_A_tempo}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Angst_tempo.png}
		\caption{Sixth subfigure} \label{fig:am_A_tempo}
	\end{subfigure}
	
	\caption{My complicated figure} \label{fig:countplots_A}
\end{figure}


\subsection{Wut}
\label{sec:Wut}

\emph{Originalaufnahmen} (\autoref{fig:de_W} und \ref{fig:am_W}) \\
Signifikanter Unterschied (p<0.05) zwischen armenischer und deutscher Hörer bei der Bewertung der Originalsprachaufnahmen für Wut.
Wut wird von beiden Kulturen am deutlichsten erkannt. Knapp über 90\% der Deutschen und über 80\% der Armenier ordnen die Signale richtig zu. Die falschen Zuordnungen verteilen sich ziemlich gleichmäßig auf die anderen Emotionen, bei den Deutschen mit Tendenz zu Freude, bei den Armeniern mit Tendenz zu Ekel.

\noindent
\emph{Grundfrequenzmanipulation} (\autoref{fig:de_W_F0} und \ref{fig:am_W_F0}) \\
Signifikant zwischen DE und AM (p<0.05)
Sowohl bei den Deutschen, als auch bei den Armeniern sinkt die Anzahl der richtigen Zuordnungen. Waehrend die Erhöhung der f0 jedoch bei den Deutschen mit einer Erhöhung der Einordnungen als Ekel und Angst einhergehen, wählen die Armenier fast ausschliesslich Ekel.
Warum?
Bei den deutschen Teilnehmern erfolgt zudem eine Zunahme der Einordnung als Angst, was damit zusammenhängen koennte, dass Wut und Angst in den Originalaufnahmen eine ähnlich hohe f0 aufweisen und es mit einer weiteren Erhoehung schwieriger wird, diese Emotionen auseinanderzuhalten.

\noindent
\emph{Tempomanipulation} (\autoref{fig:de_W_tempo} und \ref{fig:am_W_tempo}) \\
Ein schnelleres Sprechtempo führt bei beiden Kulturen dazu, dass die Emotion Wut besser erkannt wird als in den Originalaufnahmen. Jeweils über 90\% der Teilnehmer ordnen das Signal richtig zu. Freude wird als Antwort kaum noch ausgewählt, was durch die gedehnte Aussprache von Freude erklärt werden kann und passt zu der Abnahme der Zuordnungen zu Freude beim erhöhten Tempo des prosodischen Ausdrucks Freude (siehe \autoref{sec:Freude}).


\begin{figure}[t!] % "[t!]" placement specifier just for this example
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Wut.png}
		\caption{First subfigure} \label{fig:de_W}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Wut.png}
		\caption{Second subfigure} \label{fig:am_W}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Wut_F0.png}
		\caption{Third subfigure} \label{fig:de_W_F0}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Wut_F0.png}
		\caption{Fourth subfigure} \label{fig:am_W_F0}
	\end{subfigure}
	
	\medskip
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/de_Wut_tempo.png}
		\caption{Fifth subfigure} \label{fig:de_W_tempo}
	\end{subfigure}\hspace*{\fill}
	\begin{subfigure}{0.48\textwidth}
		\includegraphics[width=\linewidth]{plots/am_Wut_tempo.png}
		\caption{Sixth subfigure} \label{fig:am_W_tempo}
	\end{subfigure}
	
	\caption{My complicated figure} \label{fig:countplots_W}
\end{figure}


\chapter{Fazit}

Die Rolle der Kultur und des psosodischen Ausdrucks auf die Emotionswahrnehmung wurde untersucht. 
Es konnte gezeigt werden, dass ein kulturabhängiger Unterschied bei der Dekodierung der intendierten prosodischen Ausdrücken zwischen den deutschen und den armenischen Hörern besteht. 

Für einen detaillierteren Einblick könnte gewonnen werden, wenn das Experimetdesign statt kategorische Antwortmöglichkeiten eine gradiale Skala beinhaltet. Außerdem kann eine systematische Manipuation der Stimuli kann die Interkulturellen Varianzen innerhalb einer emotionalen Kategorie besser sichtbar machen. 
%\printbibliography[title=References]
\printbibliography

\appendix


% No section numbering at any depth ...
\setcounter{secnumdepth}{-1}

% ... such that this chapter is not numbered (like, for instance, the References chapter)
\chapter{Anhang}

% Restore section numbering (2 is the default and means that sections and subsections are numbered, but subsubsections are not)
\setcounter{secnumdepth}{2}

% Configure how sections in the appendix are numbered
\renewcommand\thesection{\Alph{section}}

\section{Fragen zur Persönlichkeit}
\label{appendix:bigfive}

Diese sind fünf Fragen zur Person nach dem Fünf-Faktoren-Model.   

\begin{itemize}
	\item Wie offen und aufgeschlossen sind Sie für neue Erfahrungen?
	\begin{enumerate}
		\item konservativ/vorsichtig
		\item etwas konservativ/vorsichtig
		\item neutral
		\item etwas erfinderisch/neugierig
		\item erfinderisch/neugierig
	\end{enumerate}
	\item Wie gewissenhaft sind Sie?
	\begin{enumerate}
		\item unbekümmert/nachlässig
		\item etwas unbekümmert/nachlässig
		\item neutral
		\item etwas effektiv/organisiert
		\item effektiv/organisiert
	\end{enumerate}
	\item Wie extrovertiert schätzen Sie sich ein?
	\begin{enumerate}
		\item zurückhaltend/reserviert
		\item etwas zurückhaltend/reserviert
		\item neutral
		\item etwas gesellig/aktiv
		\item gesellig/aktiv
	\end{enumerate}
	\item Wie verträglich schätzen Sie sich ein?	
	\begin{enumerate}
		\item wettbewerbsorientiert/antagonistisch
		\item etwas wettbewerbsorientiert/antagonistisch
		\item neutral
		\item etwas kooperativ/mitfühlend
		\item kooperativ/mitfühlend
	\end{enumerate}
	\item Wie impulsiv sind Sie?	
	\begin{enumerate}
		\item selbstsicher/ruhig
		\item etwas selbstsicher/ruhig
		\item neutral
		\item etwas emotional/mitfühlend
		\item emotional/mitfühlend
	\end{enumerate}
\end{itemize}


\noindent Die oben genannten fünf Fragen zur Persönlichkeit wurde für die armenische Version des Experimentes ins Armenische übersetzt.  

\begin{itemize}
	{\artm 
	\item Ինչպե՞ս եք վերաբերվում փոփոխություններին։
	\begin{enumerate}
		\item զգուշավոր/փոփոխամերժ
		\item որոշ չափով զգուշավոր/փոփոխամերժ
		\item չեզոք
		\item որոշ չափով հեշտ հարմարվող/հետաքրքրասեր
		\item հեշտ հարմարվող/հետաքրքրասեր
	\end{enumerate}
	\item Պարտականությունները կատարելիս հիմնականում միտված եք լինելու․․․
	\begin{enumerate}
		\item անհոգ/ոչ հետևողական		
		\item որոշ չափով անհոգ/ոչ հետևողական
		\item չեզոք
		\item որոշ չափով պարտաճանաչ/կազմակերպված
		\item պարտաճանաչ/կազմակերպված
	\end{enumerate}
	\item Համարում եք Ձեզ ավելի շփվո՞ղ, թե՞ ինքնամփոփ մարդ։
	\begin{enumerate}
		\item ինքնամփոփ/զուսպ
		\item որոշ չափով ինքնամփոփ/զուսպ
		\item չեզոք
		\item որոշ չափով շփվող/աշխույժ
		\item շփվող/աշխույժ
	\end{enumerate}
	\item Մարդկանց հետ փոխհամաձայնության գալիս ո՞ր տարբերակն է ավելի բնորոշ Ձեզ։
	\begin{enumerate}
		\item մրցակցող/հակաճառող
		\item որոշ չափով մրցակցող/հակաճառող
		\item չեզոք
		\item որոշ չափով զիջող/ապրումակցող
		\item զիջող/ապրումակցող
	\end{enumerate}
	\item Ինչպե՞ս կբնութագրեք Ձեր վարքը նյարդայնացնող իրավիճակներում։
	\begin{enumerate}
		\item հավասարակշռված/հանգիստ
		\item որոշ չափով հավասարակշռված/հանգիստ
		\item չեզոք
		\item որոշ չափով զգացմունքային/բռնկվող
		\item զգացմունքային/բռնկվող 
	\end{enumerate}
}
\end{itemize}





\newpage

\section{Das armenische Alphabet}
\label{appendix:alphabeth_am}

Das moderne armenische Alphabet besteht aus 39 Grapheme. Jedes Phonem im modernen Ostarmenisch kann mindestens durch ein Graphem dargestellt werden. Dahingegen befinden sich manche Buchstaben im Alphabet, die einem Phonem entsprechen. \\    

{
\renewcommand{\arraystretch}{1.2}
\centering
\begin{minipage}{0.5\textwidth}
\begin{tabular}{@{}|l|l|l|}
	
\toprule
	
\textbf{Gross} & \textbf{Klein} & \textbf{IPA} \\
	
\midrule
		
{\artm A} &	{\artm a} & \textipa{A}\\\hline
{\artm  B} & {\artm b} & \textipa{b}\\\hline
{\artm G} & {\artm g} & \textipa{g}\\\hline
{\artm D} & {\artm d} & \textipa{d}\\\hline
{\artm E} & {\artm e} & \textipa{E} (\textipa{jE})\\\hline
{\artm Z} & {\artm z} & \textipa{z}\\\hline
{\artm E'} & {\artm e'} & \textipa{E}\\\hline
{\artm U'} & {\artm u'} & \textipa{@}\\\hline
{\artm T'} & {\artm t'} & \textipa{t\super{h}}\\\hline
{\artm Z'} & {\artm g'} & \textipa{Z}\\\hline
{\artm I} & {\artm I} & \textipa{i}\\\hline
{\artm L} & {\artm l} & \textipa{l}\\\hline
{\artm X} & {\artm x} & \textipa{X}\\\hline
{\artm C'} & {\artm c'} & \texttslig\\\hline
{\artm K} & {\artm k} & \textipa{k}\\\hline
{\artm H} & {\artm h} & \textipa{h}\\\hline
{\artm DZ} & {\artm dz} & \textdzlig \\\hline
{\artm GH} & {\artm gh} & \textipa{K}\\\hline
{\artm J'} & {\artm j'} & \textteshlig \\\hline
{\artm M} & {\artm m} & \textipa{m}\\\hline
\end{tabular}
\end{minipage} \hfill
\begin{minipage}{0.5\textwidth}
\begin{tabular}{@{}|l|l|l|}	
	\toprule	
	\textbf{Gross} & \textbf{Klein} & \textbf{IPA} \\	
	\midrule
{\artm Y} & {\artm y} & \textipa{j}\\\hline
{\artm N} & {\artm n} & \textipa{n}\\\hline
{\artm SH} & {\artm sh} & \textipa{S}\\\hline
{\artm O} & {\artm o} & \textipa{O} (\textipa{vO})\\\hline
{\artm CH} & {\artm ch} & \textteshlig{\super{h}} \\\hline
{\artm P} & {\artm p} & \textipa{p}\\\hline
{\artm J} & {\artm j} & \textdyoghlig\\\hline
{\artm R} & {\artm r} & \textipa{r}\\\hline
{\artm S} & {\artm s} & \textipa{s}\\\hline
{\artm V} & {\artm v} & \textipa{v}\\\hline
{\artm T} & {\artm t} & \textipa{t}\\\hline
{\artm R} & {\artm r} & \textfishhookr \\\hline
{\artm C} & {\artm c} & \texttslig{\super{h}}\\\hline
{\artm Ow} & {\artm ow} & \textipa{u}\\\hline
{\artm PH} & {\artm ph} & \textipa{p\super{h}}\\\hline
{\artm Q} & {\artm q} & \textipa{k\super{h}}\\\hline
 & {\artm ev} & \textipa{Ev} (\textipa{jEv})\\\hline
{\artm O'} & {\artm o'} & \textipa{O}\\\hline
{\artm F} & {\artm f} & \textipa{f}\\\hline	
\bottomrule
\end{tabular}
\end{minipage}
}

\noindent Manche Grapheme haben mehr als eine Ausspracheoption. Die Aussprache der Wortinitialen Buchstaben entspricht der in Klammern. 

Im Armenischen gibt es kein Großbuchstabe für {\artm ev} [\textipa{Ev}] , [\textipa{jE}], stattdessen werden die Buchstaben {\artm E} [\textipa{E}] , [\textipa{jEv}] und {\artm v} [\textipa{v}]  benutzt. Beispiel:

\end{document}
