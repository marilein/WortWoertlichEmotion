% $ biblatex auxiliary file $
% $ biblatex bbl format version 2.9 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{apa/global//global/global}
    \entry{Ackermann2004}{article}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=6410cdf76c75711d897b5f65660e64e9}{%
           family={Ackermann},
           familyi={A\bibinitperiod},
           given={H.},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=d346f550591b07080e530f283576480c}{%
           family={Hertrich},
           familyi={H\bibinitperiod},
           given={I.},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=be44333e1c95f053bb976a01d16b5b84}{%
           family={Crodd},
           familyi={C\bibinitperiod},
           given={W.},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=7d16f7a322b8883a9823d1649ecca79d}{%
           family={Wildgruber},
           familyi={W\bibinitperiod},
           given={D.},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{0b5d72a326e19c2a120f75e319eccc2d}
      \strng{fullhash}{f80cbf7bdf59ae3c3ea888fac35de219}
      \strng{bibnamehash}{f80cbf7bdf59ae3c3ea888fac35de219}
      \strng{authorbibnamehash}{f80cbf7bdf59ae3c3ea888fac35de219}
      \strng{authornamehash}{0b5d72a326e19c2a120f75e319eccc2d}
      \strng{authorfullhash}{f80cbf7bdf59ae3c3ea888fac35de219}
      \field{sortinit}{A}
      \field{sortinithash}{a3dcedd53b04d1adfd5ac303ecd5e6fa}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Besides a sequence of words, spoken utterances are characterized by prosodic (suprasegmental) qualities such as a distinct into-nation contour ("speech melody"), loudness variations, and a rhythmic structure. In addition to a variety of linguistic and pragmatic functions, these features may reflect a speaker's mood and, thus, contribute, concomitant with facial and gestural movements, to the nonverbal expression of emotions (affective prosody). Clinical studies yielded discrepant data on the cerebral correlates of the processing of affective prosody. Functional imaging provides a more recent approach to the analysis of brain-behaviour relationships. The available investigations indicate two successive stages of the perceptual encoding of affective prosody: (a) predominant right-hemisphere processing of intonation contours within posterior parts of the superior temporal gyrus, (b) evaluation of the conveyed emotion at the level of bilateral orbitofrontal cortex. These findings corroborate and extend the model of a more proficient analysis and short-term storage of tonal information within the right cerebral hemisphere.}
      \field{issn}{03024350}
      \field{journaltitle}{Aktuelle Neurologie}
      \field{number}{9}
      \field{title}{{"Das h{ö}ren von gef{ü}hlen": Funktionell-neuro-anatomische grundlagen der verarbeitung affektiver prosodie}}
      \field{volume}{31}
      \field{year}{2004}
      \field{pages}{449\bibrangedash 460}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1055/s-2004-828377
      \endverb
      \verb{file}
      \verb :home/mhemmer/Downloads/MA-related/Literatur/emotion and prosody/Ackermann{\_}Akt{\_}Neurol{\_}31{\_}446{\_}2004.pdf:pdf
      \endverb
    \endentry
    \entry{Ackermann2014c}{article}{}
      \name{author}{3}{}{%
        {{uniquename=0,uniquepart=base,hash=f576c55a716947b7a108470909963a9c}{%
           family={Ackermann},
           familyi={A\bibinitperiod},
           given={Hermann},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=5e1ad018acf96961db7937adbc4ff926}{%
           family={Hage},
           familyi={H\bibinitperiod},
           given={Steffen\bibnamedelima R.},
           giveni={S\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=a7371e89e21174f3d6654e3990ea8ede}{%
           family={Ziegler},
           familyi={Z\bibinitperiod},
           given={Wolfram},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{d7fb0a83e55f83a35e5c20542a8cb55f}
      \strng{fullhash}{0915edb5ac10c5c49c6392bd523cd6ef}
      \strng{bibnamehash}{0915edb5ac10c5c49c6392bd523cd6ef}
      \strng{authorbibnamehash}{0915edb5ac10c5c49c6392bd523cd6ef}
      \strng{authornamehash}{d7fb0a83e55f83a35e5c20542a8cb55f}
      \strng{authorfullhash}{0915edb5ac10c5c49c6392bd523cd6ef}
      \field{sortinit}{A}
      \field{sortinithash}{a3dcedd53b04d1adfd5ac303ecd5e6fa}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this response to commentaries, we revisit the two main arguments of our target article. Based on data drawn from a variety of research areas - vocal behavior in nonhuman primates, speech physiology and pathology, neurobiology of basal ganglia functions, motor skill learning, paleoanthropological concepts - the target article, first, suggests a two-stage model of the evolution of the crucial motor prerequisites of spoken language within the hominin lineage: (1) monosynaptic refinement of the projections of motor cortex to brainstem nuclei steering laryngeal muscles, and (2) subsequent vocal-laryngeal elaboration of cortico-basal ganglia circuits, driven by human-specific FOXP2 mutations. Second, as concerns the ontogenetic development of verbal communication, age-dependent interactions between the basal ganglia and their cortical targets are assumed to contribute to the time course of the acquisition of articulate speech. Whereas such a phylogenetic reorganization of cortico-striatal circuits must be considered a necessary prerequisite for ontogenetic speech acquisition, the 30 commentaries - addressing the whole range of data sources referred to - point at several further aspects of acoustic communication which have to be added to or integrated with the presented model. For example, the relationships between vocal tract movement sequencing - the focus of the target article - and rhythmical structures of movement organization, the connections between speech motor control and the central-auditory and central-visual systems, the impact of social factors upon the development of vocal behavior (in nonhuman primates and in our species), and the interactions of ontogenetic speech acquisition - based upon FOXP2-driven structural changes at the level of the basal ganglia - with preceding subvocal stages of acoustic communication as well as higher-order (cognitive) dimensions of phonological development. Most importantly, thus, several promising future research directions unfold from these contributions - accessible to clinical studies and functional imaging in our species as well as experimental investigations in nonhuman primates.}
      \field{issn}{14691825}
      \field{journaltitle}{Behavioral and Brain Sciences}
      \field{number}{6}
      \field{title}{{Phylogenetic reorganization of the basal ganglia: A necessary, but not the only, bridge over a primate Rubicon of acoustic communication}}
      \field{volume}{37}
      \field{year}{2014}
      \field{pages}{577\bibrangedash 604}
      \range{pages}{28}
      \verb{doi}
      \verb 10.1017/S0140525X1400003X
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ackermann, Hage, Ziegler - 2014 - Phylogenetic reorganization of the basal ganglia A necessary, but not the only, bridge over a primate.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb https://www.researchgate.net/publication/279296562{\_}Phylogenetic{\_}reorganization{\_}of{\_}the{\_}basal{\_}ganglia{\_}A{\_}necessary{\_}but{\_}not{\_}the{\_}only{\_}bridge{\_}over{\_}a{\_}primate{\_}Rubicon{\_}of{\_}acoustic{\_}communication
      \endverb
      \verb{url}
      \verb https://www.researchgate.net/publication/279296562%7B%5C_%7DPhylogenetic%7B%5C_%7Dreorganization%7B%5C_%7Dof%7B%5C_%7Dthe%7B%5C_%7Dbasal%7B%5C_%7Dganglia%7B%5C_%7DA%7B%5C_%7Dnecessary%7B%5C_%7Dbut%7B%5C_%7Dnot%7B%5C_%7Dthe%7B%5C_%7Donly%7B%5C_%7Dbridge%7B%5C_%7Dover%7B%5C_%7Da%7B%5C_%7Dprimate%7B%5C_%7DRubicon%7B%5C_%7Dof%7B%5C_%7Dacoustic%7B%5C_%7Dcommunication
      \endverb
    \endentry
    \entry{Banse1996}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=d7d5999fbadceb469a606a1c405dd461}{%
           family={Banse},
           familyi={B\bibinitperiod},
           given={Rainer},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=b93b62dd7440b6815e9dccdbf5a37c4c}{%
           family={Scherer},
           familyi={S\bibinitperiod},
           given={Klaus\bibnamedelima R.},
           giveni={K\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{a0aae3044dcd09c142840502b9834dc3}
      \strng{fullhash}{a0aae3044dcd09c142840502b9834dc3}
      \strng{bibnamehash}{a0aae3044dcd09c142840502b9834dc3}
      \strng{authorbibnamehash}{a0aae3044dcd09c142840502b9834dc3}
      \strng{authornamehash}{a0aae3044dcd09c142840502b9834dc3}
      \strng{authorfullhash}{a0aae3044dcd09c142840502b9834dc3}
      \field{sortinit}{B}
      \field{sortinithash}{8de16967003c7207dae369d874f1456e}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Professional actors' portrayals of 14 emotions varying in intensity and valence were presented to judges. The results on decoding replicate earlier findings on the ability of judges to infer vocally expressed emotions with much-better-than-chance accuracy, including consistently found differences in the recognizability of different emotions. A total of 224 portrayals were subjected to digital acoustic analysis to obtain profiles of vocal parameters for different emotions. The data suggest that vocal parameters not only index the degree of intensity typical for different emotions but also differentiate valence or quality aspects. The data are also used to test theoretical predictions on vocal patterning based on the component process model of emotion (K. R. Scherer, 1986). Although most hypotheses are supported, some need to be revised on the basis of the empirical evidence. Discriminant analysis and jackknifing show remarkably high hit rates and patterns of confusion that closely mirror those found for listener-judges.}
      \field{annotation}{* vocal emotional profiles for each emotion * naturalness of acted emotions * accuracy of prediction of emotions}
      \field{issn}{00223514}
      \field{journaltitle}{Journal of Personality and Social Psychology}
      \field{number}{3}
      \field{title}{{Acoustic Profiles in Vocal Emotion Expression}}
      \field{volume}{70}
      \field{year}{1996}
      \field{pages}{614\bibrangedash 636}
      \range{pages}{23}
      \verb{doi}
      \verb 10.1037/0022-3514.70.3.614
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Banse, Scherer - 1996 - Acoustic Profiles in Vocal Emotion Expression.pdf:pdf
      \endverb
    \endentry
    \entry{Burkhardt2006}{article}{}
      \name{author}{6}{}{%
        {{uniquename=0,uniquepart=base,hash=e5ff884fb9a941a47822b9448757d8ca}{%
           family={Burkhardt},
           familyi={B\bibinitperiod},
           given={F},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=2a03b583a88c1af6eeb38a5f2676b91a}{%
           family={Audibert},
           familyi={A\bibinitperiod},
           given={N},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=0b726db4520cea3d27e3096bae86a193}{%
           family={Malatesta},
           familyi={M\bibinitperiod},
           given={L},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=72ac7bafeec76c97145bcedc6de94df3}{%
           family={T{ü}rk},
           familyi={T\bibinitperiod},
           given={O},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=63d551199b2d37e3ce277929c7772003}{%
           family={Arslan},
           familyi={A\bibinitperiod},
           given={L},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=f5d5b2186aa233418511d83a78a1b3c5}{%
           family={Auberge},
           familyi={A\bibinitperiod},
           given={V},
           giveni={V\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{1ec868983d068bcf53af0d283ada0538}
      \strng{fullhash}{28a005adab2ca12f71a3a0444850d04a}
      \strng{bibnamehash}{28a005adab2ca12f71a3a0444850d04a}
      \strng{authorbibnamehash}{28a005adab2ca12f71a3a0444850d04a}
      \strng{authornamehash}{1ec868983d068bcf53af0d283ada0538}
      \strng{authorfullhash}{28a005adab2ca12f71a3a0444850d04a}
      \field{sortinit}{B}
      \field{sortinithash}{8de16967003c7207dae369d874f1456e}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We report on a multilingual comparison study on the effects of prosodic changes on emotional speech. The study was conducted in France, Germany, Greece and Turkey. Semantically identical sentences expressing emotional relevant content were translated into the target languages and were manipulated systematically with respect to pitch range, duration model, and jitter simulation. Perception experiments in the participating countries showed relevant effects irrespective of language. Nonetheless, some effects of language are also reported.}
      \field{journaltitle}{Speech Prosody}
      \field{number}{1}
      \field{title}{{Emotional Prosody - Does Culture Make A Difference?}}
      \field{volume}{2}
      \field{year}{2006}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burkhardt et al. - 2006 - Emotional Prosody - Does Culture Make A Difference.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.6152{\&}rep=rep1{\&}type=pdf
      \endverb
      \verb{url}
      \verb http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.6152%7B%5C&%7Drep=rep1%7B%5C&%7Dtype=pdf
      \endverb
    \endentry
    \entry{Charpentier1989}{misc}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=d2eb03f9881e6ad067020d271e2de281}{%
           family={Charpentier},
           familyi={C\bibinitperiod},
           given={Francis},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=9a27cfd06e24e248dcf090e4f986e98d}{%
           family={Mouunes},
           familyi={M\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{5ab6ddcc6dfdbc3add49e340fa8f8e3d}
      \strng{fullhash}{5ab6ddcc6dfdbc3add49e340fa8f8e3d}
      \strng{bibnamehash}{5ab6ddcc6dfdbc3add49e340fa8f8e3d}
      \strng{authorbibnamehash}{5ab6ddcc6dfdbc3add49e340fa8f8e3d}
      \strng{authornamehash}{5ab6ddcc6dfdbc3add49e340fa8f8e3d}
      \strng{authorfullhash}{5ab6ddcc6dfdbc3add49e340fa8f8e3d}
      \field{sortinit}{C}
      \field{sortinithash}{4c244ceae61406cdc0cc2ce1cb1ff703}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We review in a common framework several algorithms that have been proposed recently, in order to improve the voice quality of speech synthesis using diphones [1-3]. These algorithms are based on a pitch-synchronous overlap-add (PSOLA) approach for modifying the speech prosody and concatenating diphone waveforms. The modifications of the speech signal are performed either in the frequencydomain (FD-PSOLA), using the Fast Fourier Transform, or directly in the time domain (TD-P SOLA), depending on the length of the window used in the synthesis process. The frequency domain approach is capable or a great flexibility in modifying the spectral characteristics of the speech signal, while the time domain approach provides very efficient solutions for the real time implementation of synthesis systems. We also discuss the different kinds of distortions involved in thesedifferent algorithms.}
      \field{title}{{PITCH-SYNCHRONOUS WA VEFORM PROCESSING TECHNIQUES FOR TEXT-TO-SPEECH SYNTHESIS USING DIPHONES}}
      \field{year}{1989}
      \verb{file}
      \verb :home/mhemmer/Downloads/MA-related/Literatur/Tools/charpenter{\_}PSOLA.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://www.iscaaspeech.org/archiveEUROSPEECH'89,
      \endverb
      \verb{url}
      \verb http://www.iscaaspeech.org/archiveEUROSPEECH'89,
      \endverb
    \endentry
    \entry{Chronaki2018}{article}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=d09d8655adadd82d7bc220a9382b1e98}{%
           family={Chronaki},
           familyi={C\bibinitperiod},
           given={Georgia},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=be55fe240e6032be28148e8ce8da680a}{%
           family={Wigelsworth},
           familyi={W\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=e49b500adb71acfc889394dcb0b1308a}{%
           family={Pell},
           familyi={P\bibinitperiod},
           given={Marc\bibnamedelima D},
           giveni={M\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=e09a920f2fc3eb183af56f56daf517b5}{%
           family={Kotz},
           familyi={K\bibinitperiod},
           given={Sonja\bibnamedelima A},
           giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{0ef4cbaf921f84cd6003e187c04ad57f}
      \strng{fullhash}{f447ba684e37a5cbd89ae2fb10a787ea}
      \strng{bibnamehash}{f447ba684e37a5cbd89ae2fb10a787ea}
      \strng{authorbibnamehash}{f447ba684e37a5cbd89ae2fb10a787ea}
      \strng{authornamehash}{0ef4cbaf921f84cd6003e187c04ad57f}
      \strng{authorfullhash}{f447ba684e37a5cbd89ae2fb10a787ea}
      \field{sortinit}{C}
      \field{sortinithash}{4c244ceae61406cdc0cc2ce1cb1ff703}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Humans have an innate set of emotions recognised universally. However, emotion recognition also depends on socio-cultural rules. Although adults recognise vocal emotions universally, they identify emotions more accurately in their native language. We examined developmental trajectories of universal vocal emotion recognition in children. Eighty native English speakers completed a vocal emotion recognition task in their native language (English) and foreign languages (Spanish, Chinese, and Arabic) expressing anger, happiness, sadness, fear, and neutrality. Emotion recognition was compared across 8-to-10, 11-to-13-year-olds, and adults. Measures of behavioural and emotional problems were also taken. Results showed that although emotion recognition was above chance for all languages, native English speaking children were more accurate in recognising vocal emotions in their native language. There was a larger improvement in recognising vocal emotion from the native language during adolescence. Vocal anger recognition did not improve with age for the non-native languages. This is the first study to demonstrate universality of vocal emotion recognition in children whilst supporting an "in-group advantage" for more accurate recognition in the native language. Findings highlight the role of experience in emotion recognition, have implications for child development in modern multicultural societies and address important theoretical questions about the nature of emotions.}
      \field{issn}{20452322}
      \field{journaltitle}{Scientific Reports}
      \field{number}{1}
      \field{title}{{The development of cross-cultural recognition of vocal emotion during childhood and adolescence}}
      \field{volume}{8}
      \field{year}{2018}
      \verb{doi}
      \verb 10.1038/s41598-018-26889-1
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chronaki et al. - Unknown - The development of cross-cultural recognition of vocal emotion during childhood and adolescence OPEN.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb www.nature.com/scientificreports
      \endverb
      \verb{url}
      \verb www.nature.com/scientificreports
      \endverb
    \endentry
    \entry{Draxler2011}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=82df7f47d2aa6a686ae0581b376a8549}{%
           family={Draxler},
           familyi={D\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{fullhash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{bibnamehash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{authorbibnamehash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{authornamehash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{authorfullhash}{82df7f47d2aa6a686ae0581b376a8549}
      \field{sortinit}{D}
      \field{sortinithash}{c438b3d5d027251ba63f5ed538d98af5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Percy is a small software framework for perception experiments via the WWW. It is implemented entirely in dynamic HTML and makes use of the new multimedia tags available in HTML5, eliminating the need for browser plug-ins or external players to display media content. With Percy, perception experiments can be run on any platform supporting HTML5, including tablet computers, smartphones or game consoles and thus access new participant populations. Percy supports touch interfaces and measures reaction times. It stores its data in a relational database system on a server. This allows immediate access to the experiment data via standard database access APIs. The system has been used for a number of experiments in German, Castilian Spanish and English. Copyright {©} 2011 ISCA.}
      \field{issn}{19909772}
      \field{journaltitle}{Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH}
      \field{title}{{Percy - An HTML5 framework for media rich web experiments on mobile devices}}
      \field{year}{2011}
      \field{pages}{3339\bibrangedash 3340}
      \range{pages}{2}
      \verb{file}
      \verb :home/mhemmer/Downloads/MA-related/Literatur/percy{\_}short.pdf:pdf
      \endverb
      \keyw{HTML5,Multilingual framework,Online experiment,Reaction times}
    \endentry
    \entry{Draxler2014}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=82df7f47d2aa6a686ae0581b376a8549}{%
           family={Draxler},
           familyi={D\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{fullhash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{bibnamehash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{authorbibnamehash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{authornamehash}{82df7f47d2aa6a686ae0581b376a8549}
      \strng{authorfullhash}{82df7f47d2aa6a686ae0581b376a8549}
      \field{sortinit}{D}
      \field{sortinithash}{c438b3d5d027251ba63f5ed538d98af5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In early 2012 the online perception experiment software Percy was deployed on a production server at our lab. Since then, 38 experiments have been made publicly available, with a total of 3078 experiment sessions. In the course of time, the software has been continuously updated and extended to adapt to changing user requirements. Web-based editors for the structure and layout of the experiments have been developed. This paper describes the system architecture, presents usage statistics, discusses typical characteristics of online experiments, and gives an outlook on ongoing work. webapp.phonetik.uni-muenchen.de/WebExperiment lists all currently active experiments.}
      \field{isbn}{9782951740884}
      \field{journaltitle}{Proceedings of the 9th International Conference on Language Resources and Evaluation, LREC 2014}
      \field{title}{{Online experiments with the Percy software framework - Experiences and some early results}}
      \field{year}{2014}
      \field{pages}{235\bibrangedash 240}
      \range{pages}{6}
      \verb{file}
      \verb :home/mhemmer/Downloads/MA-related/Literatur/percyExperiences.pdf:pdf
      \endverb
      \keyw{Online perception experiment,Results,Tool,WWW}
    \endentry
    \entry{Jadoul2018a}{article}{}
      \name{author}{3}{}{%
        {{uniquename=0,uniquepart=base,hash=837022506b7a02ab2a29e7ba03afca7e}{%
           family={Jadoul},
           familyi={J\bibinitperiod},
           given={Yannick},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=62604a5eb0c37c01837025d34c7d202f}{%
           family={Thompson},
           familyi={T\bibinitperiod},
           given={Bill},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=c13585a6c1f5528f0a7b9a0f15047884}{%
           family={Boer},
           familyi={B\bibinitperiod},
           given={Bart},
           giveni={B\bibinitperiod},
           givenun=0,
           prefix={de},
           prefixi={d\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Academic Press}%
      }
      \strng{namehash}{a456aa08d18a24071d3860f4fef515ac}
      \strng{fullhash}{493de3f25c199a4b570fccb6412028fd}
      \strng{bibnamehash}{493de3f25c199a4b570fccb6412028fd}
      \strng{authorbibnamehash}{493de3f25c199a4b570fccb6412028fd}
      \strng{authornamehash}{a456aa08d18a24071d3860f4fef515ac}
      \strng{authorfullhash}{493de3f25c199a4b570fccb6412028fd}
      \field{sortinit}{J}
      \field{sortinithash}{c45040a764d616897e7f5b30174d7b92}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper introduces Parselmouth, an open-source Python library that facilitates access to core functionality of Praat in Python, in an efficient and programmer-friendly way. We introduce and motivate the package, and present simple usage examples. Specifically, we focus on applications in data visualisation, file manipulation, audio manipulation, statistical analysis, and integration of Parselmouth into a Python-based experimental design for automated, in-the-loop manipulation of acoustic data. Parselmouth is available at https://github.com/YannickJadoul/Parselmouth.}
      \field{issn}{00954470}
      \field{journaltitle}{Journal of Phonetics}
      \field{month}{11}
      \field{title}{{Introducing Parselmouth: A Python interface to Praat}}
      \field{volume}{71}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 15}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1016/j.wocn.2018.07.001
      \endverb
      \keyw{Acoustics,Data analysis,Phonetics,Praat,Python,Software}
    \endentry
    \entry{Lieberman1962}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=3ba0829197e5e188a15044c0288d0797}{%
           family={Lieberman},
           familyi={L\bibinitperiod},
           given={Philip},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=65fcdf682b213c5c94523e646b45df37}{%
           family={Michaels},
           familyi={M\bibinitperiod},
           given={Sheldon\bibnamedelima B.},
           giveni={S\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Acoustical Society of America (ASA)}%
      }
      \strng{namehash}{36aeab0b3ac53261c3ef2287dde62959}
      \strng{fullhash}{36aeab0b3ac53261c3ef2287dde62959}
      \strng{bibnamehash}{36aeab0b3ac53261c3ef2287dde62959}
      \strng{authorbibnamehash}{36aeab0b3ac53261c3ef2287dde62959}
      \strng{authornamehash}{36aeab0b3ac53261c3ef2287dde62959}
      \strng{authorfullhash}{36aeab0b3ac53261c3ef2287dde62959}
      \field{sortinit}{L}
      \field{sortinithash}{dad3efd0836470093a7b4a7bb756eb8c}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Pitch pulses were electronically derived from the utterances an objective statement, a fearful utterance, a happy utterance, etc. A fixed-vowel POVO-type synthesizer was excited by these pitch pulses. rate, could be smoothed original speech English who each read eight neutral test sentences The pitch perturbations, envelope Tapes were recorded in certain "emotional" modes, i.e., as a question, or rapid variations in the fundamental excitation out and the POVO could be amplitude-modulated amplitude. sented, correct identification was made 44{\%} of the time. When amplitude information was added to the pitch information, modes in forced judgment tests. Results of the tests show that with unpmcessed able to correctly stant reduced the identifications 120-cps monotone in 14{\%} identifications}
      \field{issn}{0001-4966}
      \field{journaltitle}{The Journal of the Acoustical Society of America}
      \field{month}{7}
      \field{number}{7}
      \field{title}{{Some Aspects of Fundamental Frequency and Envelope Amplitude as Related to the Emotional Content of Speech}}
      \field{volume}{34}
      \field{year}{1962}
      \field{pages}{922\bibrangedash 927}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1121/1.1918222
      \endverb
      \verb{urlraw}
      \verb http://asa.scitation.org/doi/10.1121/1.1918222
      \endverb
      \verb{url}
      \verb http://asa.scitation.org/doi/10.1121/1.1918222
      \endverb
    \endentry
    \entry{Matsumoto}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=b585129e169f2ae07067549ce5bf57aa}{%
           family={Matsumoto},
           familyi={M\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b585129e169f2ae07067549ce5bf57aa}
      \strng{fullhash}{b585129e169f2ae07067549ce5bf57aa}
      \strng{bibnamehash}{b585129e169f2ae07067549ce5bf57aa}
      \strng{authorbibnamehash}{b585129e169f2ae07067549ce5bf57aa}
      \strng{authornamehash}{b585129e169f2ae07067549ce5bf57aa}
      \strng{authorfullhash}{b585129e169f2ae07067549ce5bf57aa}
      \field{sortinit}{M}
      \field{sortinithash}{2e5c2f51f7fa2d957f3206819bf86dc3}
      \field{labeldatesource}{nodate}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{Psychology Journal of Cross-Cultural Cultural Influences on the Perception of Emotion On behalf of: International Association for Cross-Cultural Psychology}}
      \verb{doi}
      \verb 10.1177/0022022189201006
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matsumoto - Unknown - Psychology Journal of Cross-Cultural Cultural Influences on the Perception of Emotion On behalf of International A.pdf:pdf
      \endverb
    \endentry
    \entry{neuber2002prosodische}{book}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=1befc197bd67f611366ec1f028864220}{%
           family={Neuber},
           familyi={N\bibinitperiod},
           given={Baldur},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Lang}%
      }
      \strng{namehash}{1befc197bd67f611366ec1f028864220}
      \strng{fullhash}{1befc197bd67f611366ec1f028864220}
      \strng{bibnamehash}{1befc197bd67f611366ec1f028864220}
      \strng{authorbibnamehash}{1befc197bd67f611366ec1f028864220}
      \strng{authornamehash}{1befc197bd67f611366ec1f028864220}
      \strng{authorfullhash}{1befc197bd67f611366ec1f028864220}
      \field{sortinit}{N}
      \field{sortinithash}{98cf339a479c0454fe09153a08675a15}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Prosodische Formen in Funktion: Leistungen der Suprasegmentalia f{ü}r das Verstehen, Behalten und die Bedeutungs (re) konstruktion}
      \field{year}{2002}
    \endentry
    \entry{Nevo2001}{article}{}
      \name{author}{3}{}{%
        {{uniquename=0,uniquepart=base,hash=e865ee04735153ae59e16aae72541fab}{%
           family={Nevo},
           familyi={N\bibinitperiod},
           given={Ofra},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=8cd20e44af0de2da889a8bf47887b2a6}{%
           family={Nevo},
           familyi={N\bibinitperiod},
           given={Baruch},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=297bcf0831798be2bc6469f22c8138ea}{%
           family={Yin},
           familyi={Y\bibinitperiod},
           given={Janie\bibnamedelimb Leong\bibnamedelima Siew},
           giveni={J\bibinitperiod\bibinitdelim L\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Taylor {\&} Francis Group}%
      }
      \strng{namehash}{71728d047d446b567f808b580f3ff013}
      \strng{fullhash}{eac0ea56f6fab7d36b3eb563076590da}
      \strng{bibnamehash}{eac0ea56f6fab7d36b3eb563076590da}
      \strng{authorbibnamehash}{eac0ea56f6fab7d36b3eb563076590da}
      \strng{authornamehash}{71728d047d446b567f808b580f3ff013}
      \strng{authorfullhash}{eac0ea56f6fab7d36b3eb563076590da}
      \field{sortinit}{N}
      \field{sortinithash}{98cf339a479c0454fe09153a08675a15}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{One hundred and nineteen undergraduate students (62 men and 57 women) of Chinese origin at the National University of Singapore answered three self-report humor questionnaires. Students were also asked to supply their favorite joke (M. A. Johnson, 1991) and a description of a person with an outstanding sense of humor (M. Crawford and D. Gressley, 1991). These responses were compared with results obtained using the same questionnaires and methods in previous studies in Israel and the United States. In general, means and reliabilities of results obtained from the Singapore study replicated those found in other countries. However, Singaporean participants reported significantly less use of humor for coping. Content analysis of jokes supplied by Singaporean students reflected conservative values: Compared with American students, they reported a significantly greater number of jokes with aggressive content and relatively fewer jokes with sexual content. Contrary to expectations, very few gender differences were found. Regardless of gender, a majority of participants nominated a man as an example of a person with an outstanding sense of humor. {©} 2001 Taylor {\&} Francis Group, LLC.}
      \field{issn}{19400888}
      \field{journaltitle}{Journal of General Psychology}
      \field{number}{2}
      \field{title}{{Singaporean humor: A cross-cultural, cross-gender comparison}}
      \field{volume}{128}
      \field{year}{2001}
      \field{pages}{143\bibrangedash 156}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1080/00221300109598904
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nevo - 2001 - Singaporean Humor A Cross-Cultural, Cross-Gender Comparison.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb https://www.researchgate.net/publication/11839116
      \endverb
      \verb{url}
      \verb https://www.researchgate.net/publication/11839116
      \endverb
      \keyw{Cultural differences in humor,Gender differences in humor,Singaporean humor}
    \endentry
    \entry{Pell2020}{article}{}
      \name{author}{3}{}{%
        {{uniquename=0,uniquepart=base,hash=e49b500adb71acfc889394dcb0b1308a}{%
           family={Pell},
           familyi={P\bibinitperiod},
           given={Marc\bibnamedelima D},
           giveni={M\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=785e01dcb71d1a57a68e443d271981e9}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Shuyi},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=e49b500adb71acfc889394dcb0b1308a}{%
           family={Pell},
           familyi={P\bibinitperiod},
           given={Marc\bibnamedelima D},
           giveni={M\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{d2db4f4a8851586558c3e542f57df03a}
      \strng{fullhash}{273c1173a8042b13f8bf19583fd1ece8}
      \strng{bibnamehash}{273c1173a8042b13f8bf19583fd1ece8}
      \strng{authorbibnamehash}{273c1173a8042b13f8bf19583fd1ece8}
      \strng{authornamehash}{d2db4f4a8851586558c3e542f57df03a}
      \strng{authorfullhash}{273c1173a8042b13f8bf19583fd1ece8}
      \field{sortinit}{P}
      \field{sortinithash}{bb5b15f2db90f7aef79bb9e83defefcb}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{To investigate the impact of culture on emotion processing, we conducted a study comparing the intensity ratings of external expression (intensity level of speaker's vocal expression) and speaker's internal feeling (intensity level participants think the speaker is experiencing). Specifically, a group of Canadian and Chinese participants categorized emotions (anger, fear, happiness, and sadness) and judged the intensity of emotional utterances in three languages (Chinese, English, and Hindi). Both groups were more accurate at recognizing emotions in their native language. In contrast to related work on facial expressions, which concluded that Eastern participants were more likely to assume that speakers experienced more intense feelings than what they expressed, compared to Western participants, our study on vocal expressions did not find similar cultural effects. Both Canadian and Chinese participants rated the internal feelings of speakers as more intense than their external expressions of emotion. Differences between studies are discussed in terms of the unique structure and social functions of vocal and facial expressions in communication and their interactions with culture.}
      \field{number}{March}
      \field{title}{{Cross-cultural Differences in Vocal Expression and Emotion Perception Cross-cultural Differences in Vocal Expression and Emotion Perception}}
      \field{year}{2020}
      \verb{doi}
      \verb 10.13140/RG.2.2.36159.46246
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pell, Zhang, Pell - 2020 - Cross-cultural Differences in Vocal Expression and Emotion Perception Cross-cultural Differences in Vocal Exp.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb https://www.researchgate.net/publication/339988042{\_}Cross-cultural{\_}Differences{\_}in{\_}Vocal{\_}Expression{\_}and{\_}Emotion{\_}Perception
      \endverb
      \verb{url}
      \verb https://www.researchgate.net/publication/339988042%7B%5C_%7DCross-cultural%7B%5C_%7DDifferences%7B%5C_%7Din%7B%5C_%7DVocal%7B%5C_%7DExpression%7B%5C_%7Dand%7B%5C_%7DEmotion%7B%5C_%7DPerception
      \endverb
    \endentry
    \entry{Provine1992}{report}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=8adb40b4721695b4eaf7b3014f5da42d}{%
           family={Provine},
           familyi={P\bibinitperiod},
           given={Robert\bibnamedelima R},
           giveni={R\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8adb40b4721695b4eaf7b3014f5da42d}
      \strng{fullhash}{8adb40b4721695b4eaf7b3014f5da42d}
      \strng{bibnamehash}{8adb40b4721695b4eaf7b3014f5da42d}
      \strng{authorbibnamehash}{8adb40b4721695b4eaf7b3014f5da42d}
      \strng{authornamehash}{8adb40b4721695b4eaf7b3014f5da42d}
      \strng{authorfullhash}{8adb40b4721695b4eaf7b3014f5da42d}
      \field{sortinit}{P}
      \field{sortinithash}{bb5b15f2db90f7aef79bb9e83defefcb}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The laugh-and/or smile-evoking potency of laughter was evaluated by observing responses of 128 subjects in three undergraduate psychology classes to laugh stimuli produced by a "laugh box." Subjects recorded whether they laughed and/or smiled during each of 10 trials, each of which consisted of an 18-sec sample of laughter, followed by 42 sec of silence. Most subjects laughed and smiled in response to the first presentation oflaughter. However, the polarity of the response changed quickly. By the 10th trial, few subjects laughed and/or smiled, and most found the stimulus "obnoxious." Although other research has described canned-laughter effects, it did not consider the hypothesis confirmed here, that laughter itself evokes laughter, perhaps by activating a laughter-specific auditory-feature detector. This result is relevant to the neurological basis of social communication, human ethology, and theories of speech production and perception.}
      \field{booktitle}{Bulletin of the Psychonomic Society}
      \field{number}{1}
      \field{title}{{Contagious laughter: Laughter is a sufficient stimulus for laughs and smiles}}
      \field{type}{techreport}
      \field{volume}{1992}
      \field{year}{1992}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Provine - 1992 - Contagious laughter Laughter is a sufficient stimulus for laughs and smiles.pdf:pdf
      \endverb
    \endentry
    \entry{Scherer2001}{report}{}
      \name{author}{7}{}{%
        {{uniquename=0,uniquepart=base,hash=563f1b1a83289f996a60d1bcc21ffba2}{%
           family={Scherer},
           familyi={S\bibinitperiod},
           given={Klaus\bibnamedelima R},
           giveni={K\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=d7d5999fbadceb469a606a1c405dd461}{%
           family={Banse},
           familyi={B\bibinitperiod},
           given={Rainer},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=426d7ee5dfd190dcb4b6ed85f68e4773}{%
           family={Wallbott},
           familyi={W\bibinitperiod},
           given={Harald\bibnamedelima G},
           giveni={H\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=56bc0ad9a8a2a057a6c0a51d6c1daaec}{%
           family={Rim{é}},
           familyi={R\bibinitperiod},
           given={Bernard},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=26a0e029363e671615a6c2bd2777310a}{%
           family={Kappas},
           familyi={K\bibinitperiod},
           given={A},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=3202a819809629c5aa45abe074be4ea2}{%
           family={Manstead},
           familyi={M\bibinitperiod},
           given={A},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=8bafacfcb504ad2a92e5657ab4cfacad}{%
           family={Ricci-Bitti},
           familyi={R\bibinithyphendelim B\bibinitperiod},
           given={P},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8b9cd57209a3b78e4b48125e5c9418ac}
      \strng{fullhash}{ec5980d74a377a094a48610e994935b2}
      \strng{bibnamehash}{ec5980d74a377a094a48610e994935b2}
      \strng{authorbibnamehash}{ec5980d74a377a094a48610e994935b2}
      \strng{authornamehash}{8b9cd57209a3b78e4b48125e5c9418ac}
      \strng{authorfullhash}{ec5980d74a377a094a48610e994935b2}
      \field{sortinit}{S}
      \field{sortinithash}{c319cff79d99c853d775f88277d4e45f}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Whereas the perception of emotion from facial expression has been extensively studied cross-culturally, little is known about judges' ability to infer emotion from vocal cues. This article reports the results from a study conducted in nine countries in Europe, the United States, and Asia on vocal emotion portrayals of anger, sadness, fear, joy, and neutral voice as produced by professional German actors. Data show an overall accuracy of 66{\%} across all emotions and countries. Although accuracy was substantially better than chance, there were sizable differences ranging from 74{\%} in Germany to 52{\%} in Indonesia. However, patterns of confusion were very similar across all countries. These data suggest the existence of similar inference rules from vocal expression across cultures. Generally, accuracy decreased with increasing language dissimilarity from German in spite of the use of language-free speech samples. It is concluded that culture-and language specific paralinguistic patterns may influence the decoding process. One of the key issues of current debate in the psychology of emotion concerns the universal-ity versus cultural relativity of emotional expression. This has important implications for the central question of the nature and function of emotion. Although there is a general consensus that both biological and cultural factors contribute to the emotion process (see Mesquita, Frijda, {\&} Scherer, 1997), the relative contribution of each of the factors, or the respective amount of variance explained, remains to be explored. An ideal way to study this issue empirically is to compare outward manifestations of emotional reactions with similar appraisals of eliciting situations in different cultures (see Scherer, 1997). Such studies could reveal the extent to which similar expression configurations indicate comparable evaluation and reaction tendencies. Unfortunately, given the difficulty of identifying and systematically studying comparable eliciting situations in different cultures, such studies have yet to be conducted. Instead, researchers in this area have adopted an indirect approach in addressing the issue. This approach is based on the assumption that, given the indisputable role of emotional expression in social communication, the ability of members of one culture to correctly 76 AUTHORS' NOTE: This research has been conducted as a collaborative research program in the context of the Coordination Europ{é}enne de la Recherche sur les Emotions (CERE), which is formed by the laboratories directed by Matty Chiva,}
      \field{booktitle}{VOCAL EMOTION EXPRESSION JOURNAL OF CROSS-CULTURAL PSYCHOLOGY}
      \field{number}{1}
      \field{title}{{EMOTION INFERENCES FROM VOCAL EXPRESSION CORRELATE ACROSS LANGUAGES AND CULTURES}}
      \field{type}{techreport}
      \field{volume}{32}
      \field{year}{2001}
      \field{pages}{76\bibrangedash 92}
      \range{pages}{17}
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scherer et al. - 2001 - EMOTION INFERENCES FROM VOCAL EXPRESSION CORRELATE ACROSS LANGUAGES AND CULTURES.pdf:pdf
      \endverb
    \endentry
    \entry{Schirmer2016a}{article}{}
      \name{author}{5}{}{%
        {{uniquename=0,uniquepart=base,hash=cf5ed90788bde67d62545fc8b953643e}{%
           family={Schirmer},
           familyi={S\bibinitperiod},
           given={Annett},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=09d02291c2c78075a8251f24c8bcdbce}{%
           family={Escoffier},
           familyi={E\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=9c2a294866c38795367ba04c6c68251b}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Xiaoqin},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=15120370ebf5b7e3e3c162eb6586132a}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Yenju},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=0afcfc8edd38cc94a3fd64bc3bddbd86}{%
           family={Penney},
           familyi={P\bibinitperiod},
           given={Trevor\bibnamedelima B.},
           giveni={T\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Frontiers Media S.A.}%
      }
      \strng{namehash}{c5915c30f638df1470d48268ea4a3d6a}
      \strng{fullhash}{65d83ecc08815cedce281ff424e1102e}
      \strng{bibnamehash}{65d83ecc08815cedce281ff424e1102e}
      \strng{authorbibnamehash}{65d83ecc08815cedce281ff424e1102e}
      \strng{authornamehash}{c5915c30f638df1470d48268ea4a3d6a}
      \strng{authorfullhash}{65d83ecc08815cedce281ff424e1102e}
      \field{sortinit}{S}
      \field{sortinithash}{c319cff79d99c853d775f88277d4e45f}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{For dynamic sounds, such as vocal expressions, duration often varies alongside speed. Compared to longer sounds, shorter sounds unfold more quickly. Here, we asked whether listeners implicitly use this confound when representing temporal regularities in their environment. In addition, we explored the role of emotions in this process. Using a mismatch negativity (MMN) paradigm, we asked participants to watch a silent movie while passively listening to a stream of task-irrelevant sounds. In Experiment 1, one surprised and one neutral vocalization were compressed and stretched to create stimuli of 378 and 600 ms duration. Stimuli were presented in four blocks, two of which used surprised and two of which used neutral expressions. In one surprised and one neutral block, short and long stimuli served as standards and deviants, respectively. In the other two blocks, the assignment of standards and deviants was reversed. We observed a climbing MMN-like negativity shortly after deviant onset, which suggests that listeners implicitly track sound speed and detect speed changes. Additionally, this MMN-like effect emerged earlier and was larger for long than short deviants, suggesting greater sensitivity to duration increments or slowing down than to decrements or speeding up. Last, deviance detection was facilitated in surprised relative to neutral blocks, indicating that emotion enhances temporal processing. Experiment 2 was comparable to Experiment 1 with the exception that sounds were spectrally rotated to remove vocal emotional content. This abolished the emotional processing benefit, but preserved the other effects. Together, these results provide insights into listener sensitivity to sound speed and raise the possibility that speed biases duration judgements implicitly in a feed-forward manner. Moreover, this bias may be amplified for duration increments relative to decrements and within an emotional relative to a neutral stimulus context.}
      \field{issn}{16641078}
      \field{journaltitle}{Frontiers in Psychology}
      \field{number}{JAN}
      \field{title}{{Detecting temporal change in dynamic sounds: On the role of stimulus duration, speed, and emotion}}
      \field{volume}{6}
      \field{year}{2016}
      \verb{doi}
      \verb 10.3389/fpsyg.2015.02055
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schirmer et al. - 2016 - Detecting temporal change in dynamic sounds On the role of stimulus duration, speed, and emotion.pdf:pdf
      \endverb
      \keyw{Auditory change detection,Event-related potentials,Interval timing,Preattentive,Prosody,Sex differences,Vocal affect}
    \endentry
    \entry{VanLancker1973a}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=b6abeeed232f0fe7a8be40e918ff7b6b}{%
           family={{Van Lancker}},
           familyi={V\bibinitperiod},
           given={Diana},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=a0cb871bd2d8895b881ec17f8cf3fd7c}{%
           family={Fromkin},
           familyi={F\bibinitperiod},
           given={Victoria\bibnamedelima A.},
           giveni={V\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Elsevier BV}%
      }
      \strng{namehash}{00c2e1d78c992b75a68a7fec188572fa}
      \strng{fullhash}{00c2e1d78c992b75a68a7fec188572fa}
      \strng{bibnamehash}{00c2e1d78c992b75a68a7fec188572fa}
      \strng{authorbibnamehash}{00c2e1d78c992b75a68a7fec188572fa}
      \strng{authornamehash}{00c2e1d78c992b75a68a7fec188572fa}
      \strng{authorfullhash}{00c2e1d78c992b75a68a7fec188572fa}
      \field{sortinit}{V}
      \field{sortinithash}{02432525618c08e2b03cac47c19764af}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In past dichotic listening studies, linguistic stimuli have shown a right ear advantage, implying left hemisphere dominance for language processing, while other stimuli incorporating pitch distinctions have shown no ear perference or a left ear (right hemisphere) advantage. Ear preferences in tone language speakers were compared for 3 sets of stimuli: (a) pitch differences within language stimuli (tone-words in the tone language, Thai); (b) language stimuli without pitch differences (consonant-vowel words on mid-tone); and (c) pitch differences alone (hums). Results from 22 native Thai speakers demonstrate that tone-words and consonant-words are better heard at the right ear, while the hums show no ear effect. Preliminary results on 14 English-speaking Ss suggest that the consonant-words give the usual right ear effect, while the tone-words and the hums do not. It is concluded that pitch discrimination is lateralized to the left hemisphere when the pitch differences are linguistically processed. (47 ref.)}
      \field{issn}{00954470}
      \field{journaltitle}{Journal of Phonetics}
      \field{month}{4}
      \field{number}{2}
      \field{title}{{Hemispheric specialization for pitch and “tone”: Evidence from Thai}}
      \field{volume}{1}
      \field{year}{1973}
      \field{pages}{101\bibrangedash 109}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1016/s0095-4470(19)31414-7
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Lancker, Fromkin - 1973 - Hemispheric specialization for pitch and “tone” Evidence from Thai.pdf:pdf
      \endverb
    \endentry
    \entry{Wendt2007}{book}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=e1953ee9c3aa53ffc9230df11c7609c0}{%
           family={Wendt},
           familyi={W\bibinitperiod},
           given={Beate},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Frankfurt am Main}%
      }
      \list{publisher}{1}{%
        {P. Lang}%
      }
      \strng{namehash}{e1953ee9c3aa53ffc9230df11c7609c0}
      \strng{fullhash}{e1953ee9c3aa53ffc9230df11c7609c0}
      \strng{bibnamehash}{e1953ee9c3aa53ffc9230df11c7609c0}
      \strng{authorbibnamehash}{e1953ee9c3aa53ffc9230df11c7609c0}
      \strng{authornamehash}{e1953ee9c3aa53ffc9230df11c7609c0}
      \strng{authorfullhash}{e1953ee9c3aa53ffc9230df11c7609c0}
      \field{sortinit}{W}
      \field{sortinithash}{1af34bd8c148ffb32de1494636b49713}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{9783631563816}
      \field{title}{{Analysen emotionaler Prosodie}}
      \field{year}{2007}
    \endentry
    \entry{Wendt2006}{article}{}
      \name{author}{5}{}{%
        {{uniquename=0,uniquepart=base,hash=e1953ee9c3aa53ffc9230df11c7609c0}{%
           family={Wendt},
           familyi={W\bibinitperiod},
           given={Beate},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=85f6323c044ecff8801e9bf01cff471a}{%
           family={Brechmann},
           familyi={B\bibinitperiod},
           given={Andr{é}},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=9dfb90b5d1850aad67ae5213249f4b2f}{%
           family={Gaschler-Markefski},
           familyi={G\bibinithyphendelim M\bibinitperiod},
           given={Birgit},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=83cf6bb86c987d00ea8367061e51de61}{%
           family={Scheich},
           familyi={S\bibinitperiod},
           given={Henning},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=f576c55a716947b7a108470909963a9c}{%
           family={Ackermann},
           familyi={A\bibinitperiod},
           given={Hermann},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3f10cb670484b0a36cd46a2b94ab8bb0}
      \strng{fullhash}{2507dda1527e9e3e02183d22e8bc0eeb}
      \strng{bibnamehash}{2507dda1527e9e3e02183d22e8bc0eeb}
      \strng{authorbibnamehash}{2507dda1527e9e3e02183d22e8bc0eeb}
      \strng{authornamehash}{3f10cb670484b0a36cd46a2b94ab8bb0}
      \strng{authorfullhash}{2507dda1527e9e3e02183d22e8bc0eeb}
      \field{sortinit}{W}
      \field{sortinithash}{1af34bd8c148ffb32de1494636b49713}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The aim of the present fMRI-study was to investigate the influence of different word prosodies on the activation of the auditory cortex (AC) of 24 subjects. Pseudowords and semantically neutral words were presented with neutral prosody in experiment I and with emotional prosodies in experiment II. We applied two lexical tasks i.e. detecting words or pseudowords. The control task was to detect pure tones. In both studies there was a typical left lateralized activation for speech perception on planum temporale (T3). This territory as part of Wernicke's area is specifically involved in speech perception. A right lateralization simply dependent on prosodic versus neutral content of speech stimuli, as suggested by some literature, is not supported by the current results. In our experiments the emotional information was task-irrelevant and even distracted from the lexical task. Namely, the performance in the detection of words and pseudowords was significantly better in the prosodically neutral condition. Thus, the current results contribute to the clarification of the controversial issue whether prosodies lateralize brain activation to the right, i.e. if lexical rather than prosodic information is in the focus of a task involving prosodic material, a right hemisphere dominance cannot be expected.}
      \field{journaltitle}{Proceedings of the 3rd International Conference on Speech Prosody (SP2006)}
      \field{title}{{Lateralized processing in human auditory cortex during the perception of emotional prosody}}
      \field{year}{2006}
      \field{pages}{2\bibrangedash 5}
      \range{pages}{4}
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wendt et al. - Unknown - Lateralized processing in human auditory cortex during the perception of emotional prosody.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://www.isca-speech.org/archive
      \endverb
      \verb{url}
      \verb http://www.isca-speech.org/archive
      \endverb
    \endentry
    \entry{Wendt2003}{article}{}
      \name{author}{7}{}{%
        {{uniquename=0,uniquepart=base,hash=e1953ee9c3aa53ffc9230df11c7609c0}{%
           family={Wendt},
           familyi={W\bibinitperiod},
           given={Beate},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=c66ee64ea70c4f127d657b30f2de5490}{%
           family={Hufnagel},
           familyi={H\bibinitperiod},
           given={Klaus},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=85f6323c044ecff8801e9bf01cff471a}{%
           family={Brechmann},
           familyi={B\bibinitperiod},
           given={Andr{é}},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=9dfb90b5d1850aad67ae5213249f4b2f}{%
           family={Gaschler-Markefski},
           familyi={G\bibinithyphendelim M\bibinitperiod},
           given={Birgit},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=721425c09f6d5d713f9610e84bee134a}{%
           family={Tiedge},
           familyi={T\bibinitperiod},
           given={J{ü}rgen},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=f576c55a716947b7a108470909963a9c}{%
           family={Ackermann},
           familyi={A\bibinitperiod},
           given={Hermann},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=83cf6bb86c987d00ea8367061e51de61}{%
           family={Scheich},
           familyi={S\bibinitperiod},
           given={Henning},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3f10cb670484b0a36cd46a2b94ab8bb0}
      \strng{fullhash}{a493cdfe8e6197fe2c39adc57aa1bc98}
      \strng{bibnamehash}{a493cdfe8e6197fe2c39adc57aa1bc98}
      \strng{authorbibnamehash}{a493cdfe8e6197fe2c39adc57aa1bc98}
      \strng{authornamehash}{3f10cb670484b0a36cd46a2b94ab8bb0}
      \strng{authorfullhash}{a493cdfe8e6197fe2c39adc57aa1bc98}
      \field{sortinit}{W}
      \field{sortinithash}{1af34bd8c148ffb32de1494636b49713}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0093934X}
      \field{journaltitle}{Brain and Language}
      \field{number}{1}
      \field{title}{{A method for creation and validation of a natural spoken language corpus used for prosodic and speech perception}}
      \field{volume}{87}
      \field{year}{2003}
      \field{pages}{187}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1016/s0093-934x(03)00263-3
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wendt et al. - 2003 - A method for creation and validation of a natural spoken language corpus used for prosodic and speech perception.pdf:pdf
      \endverb
    \endentry
    \entry{Wendt2002}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=e1953ee9c3aa53ffc9230df11c7609c0}{%
           family={Wendt},
           familyi={W\bibinitperiod},
           given={Beate},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=83cf6bb86c987d00ea8367061e51de61}{%
           family={Scheich},
           familyi={S\bibinitperiod},
           given={Henning},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e5057ac56054bc89dc621ee5b26dfae7}
      \strng{fullhash}{e5057ac56054bc89dc621ee5b26dfae7}
      \strng{bibnamehash}{e5057ac56054bc89dc621ee5b26dfae7}
      \strng{authorbibnamehash}{e5057ac56054bc89dc621ee5b26dfae7}
      \strng{authornamehash}{e5057ac56054bc89dc621ee5b26dfae7}
      \strng{authorfullhash}{e5057ac56054bc89dc621ee5b26dfae7}
      \field{sortinit}{W}
      \field{sortinithash}{1af34bd8c148ffb32de1494636b49713}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Previous studies on prosody perception showed inconsistent results concerning the functional role of the hemispheres. One argument for this might be the stimulus material was not sufficiently evaluated. Thus, we developed a corpus which fulfils this requirement. The "Magdeburger Prosodie-Korpus" which was specifically developed for the requirements of fMRI and MEG studies contains two parts. The first part consists of German nouns, the second part of pseudo-words, with both parts being spoken with different emotional prosodies by an actor and an actress. All nouns were evaluated with respect to the emotional connotation (positive, negative, neutral) of their semantic content. The results showed that only a small number of nouns received the same emotional assessment from the participants. The different emotional prosodies of the pseudo-words were assessed by a group of expert (phonetician) and non-expert listeners who are all native German speakers. All emotional prosodies (happiness, sadness, fear, anger, disgust, and neutral), spoken by the man and the woman, were identified by more than 70{\%} of all listeners, except for sadness of the man. There were no significant differences with respect to the gender of the listeners or the speakers. The acoustic analysis showed differences in specific acoustic features of the various emotional prosodies, for example, pitch contour, duration, stress, and intensity. The results were added to the database of the "Magdeburger Prosodie-Korpus".}
      \field{title}{{The “ Magdeburger Prosodie-Korpus ”}}
      \field{year}{2002}
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wendt, Scheich - 2002 - The “ Magdeburger Prosodie-Korpus ”.pdf:pdf
      \endverb
    \endentry
    \entry{Wildgruber2006}{misc}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=7d16f7a322b8883a9823d1649ecca79d}{%
           family={Wildgruber},
           familyi={W\bibinitperiod},
           given={D.},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=6410cdf76c75711d897b5f65660e64e9}{%
           family={Ackermann},
           familyi={A\bibinitperiod},
           given={H.},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=0ff5101f3d32c4596dbaa701c0993835}{%
           family={Kreifelts},
           familyi={K\bibinitperiod},
           given={B.},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=633f28feeada51a5f3933314ffd494fa}{%
           family={Ethofer},
           familyi={E\bibinitperiod},
           given={T.},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Elsevier}%
      }
      \strng{namehash}{0214bc1ae19884768db3601f42ae7c7f}
      \strng{fullhash}{e637a4f93e575ae73499e11b7ca93d0a}
      \strng{bibnamehash}{e637a4f93e575ae73499e11b7ca93d0a}
      \strng{authorbibnamehash}{e637a4f93e575ae73499e11b7ca93d0a}
      \strng{authornamehash}{0214bc1ae19884768db3601f42ae7c7f}
      \strng{authorfullhash}{e637a4f93e575ae73499e11b7ca93d0a}
      \field{sortinit}{W}
      \field{sortinithash}{1af34bd8c148ffb32de1494636b49713}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{During acoustic communication in humans, information about a speaker's emotional state is predominantly conveyed by modulation of the tone of voice (emotional or affective prosody). Based on lesion data, a right hemisphere superiority for cerebral processing of emotional prosody has been assumed. However, the available clinical studies do not yet provide a coherent picture with respect to interhemispheric lateralization effects of prosody recognition and intrahemispheric localization of the respective brain regions. To further delineate the cerebral network engaged in the perception of emotional tone, a series of experiments was carried out based upon functional magnetic resonance imaging (fMRI). The findings obtained from these investigations allow for the separation of three successive processing stages during recognition of emotional prosody: (1) extraction of suprasegmental acoustic information predominantly subserved by right-sided primary and higher order acoustic regions; (2) representation of meaningful suprasegmental acoustic sequences within posterior aspects of the right superior temporal sulcus; (3) explicit evaluation of emotional prosody at the level of the bilateral inferior frontal cortex. Moreover, implicit processing of affective intonation seems to be bound to subcortical regions mediating automatic induction of specific emotional reactions such as activation of the amygdala in response to fearful stimuli. As concerns lower level processing of the underlying suprasegmental acoustic cues, linguistic and emotional prosody seem to share the same right hemisphere neural resources. Explicit judgment of linguistic aspects of speech prosody, however, appears to be linked to left-sided language areas whereas bilateral orbitofrontal cortex has been found involved in explicit evaluation of emotional prosody. These differences in hemispheric lateralization effects might explain that specific impairments in nonverbal emotional communication subsequent to focal brain lesions are relatively rare clinical observations as compared to the more frequent aphasic disorders. {©} 2006 Elsevier B.V. All rights reserved.}
      \field{booktitle}{Progress in Brain Research}
      \field{issn}{00796123}
      \field{month}{1}
      \field{title}{{Chapter 13 Cerebral processing of linguistic and emotional prosody: fMRI studies}}
      \field{volume}{156}
      \field{year}{2006}
      \field{pages}{249\bibrangedash 268}
      \range{pages}{20}
      \verb{doi}
      \verb 10.1016/S0079-6123(06)56013-3
      \endverb
      \keyw{affect,communication,emotion,fMRI,intonation,language,lateralization,prosody}
    \endentry
    \entry{Ye2020}{article}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=f479a5bc4643d82a2d3d0fade3e8e0fd}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Yongchao},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=fb67f3e4575f5065b3df180b0e2749be}{%
           family={Lao},
           familyi={L\bibinitperiod},
           given={Lingjie},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=854e6e7df580f86273c7ea1f2e0848a6}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Diqun},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=f355ea6c678f3fc0f23b02984a9fd48f}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Rangding},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Hindawi Limited}%
      }
      \strng{namehash}{6f062e1d6f0b02dc927976ef5d2b2183}
      \strng{fullhash}{0588b2f06a4de1bedc08b90428517f9e}
      \strng{bibnamehash}{0588b2f06a4de1bedc08b90428517f9e}
      \strng{authorbibnamehash}{0588b2f06a4de1bedc08b90428517f9e}
      \strng{authornamehash}{6f062e1d6f0b02dc927976ef5d2b2183}
      \strng{authorfullhash}{0588b2f06a4de1bedc08b90428517f9e}
      \field{sortinit}{Y}
      \field{sortinithash}{6ae2ff5458ff901249c2745238c951b7}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Pitch shifting is a common voice editing technique in which the original pitch of a digital voice is raised or lowered. It is likely to be abused by the malicious attacker to conceal his/her true identity. Existing forensic detection methods are no longer effective for weakly pitch-shifted voice. In this paper, we proposed a convolutional neural network (CNN) to detect not only strongly pitch-shifted voice but also weakly pitch-shifted voice of which the shifting factor is less than ±4 semitones. Specifically, linear frequency cepstral coefficients (LFCC) computed from power spectrums are considered and their dynamic coefficients are extracted as the discriminative features. And the CNN model is carefully designed with particular attention to the input feature map, the activation function and the network topology. We evaluated the algorithm on voices from two datasets with three pitch shifting software. Extensive results show that the algorithm achieves high detection rates for both binary and multiple classifications.}
      \field{issn}{16877586}
      \field{journaltitle}{International Journal of Digital Multimedia Broadcasting}
      \field{title}{{Identification of Weakly Pitch-Shifted Voice Based on Convolutional Neural Network}}
      \field{volume}{2020}
      \field{year}{2020}
      \verb{doi}
      \verb 10.1155/2020/8927031
      \endverb
      \verb{file}
      \verb :home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ye et al. - 2020 - Identification of Weakly Pitch-Shifted Voice Based on Convolutional Neural Network.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb https://www.researchgate.net/publication/338423791{\_}Identification{\_}of{\_}Weakly{\_}Pitch-Shifted{\_}Voice{\_}Based{\_}on{\_}Convolutional{\_}Neural{\_}Network
      \endverb
      \verb{url}
      \verb https://www.researchgate.net/publication/338423791%7B%5C_%7DIdentification%7B%5C_%7Dof%7B%5C_%7DWeakly%7B%5C_%7DPitch-Shifted%7B%5C_%7DVoice%7B%5C_%7DBased%7B%5C_%7Don%7B%5C_%7DConvolutional%7B%5C_%7DNeural%7B%5C_%7DNetwork
      \endverb
    \endentry
  \enddatalist
  \missing{)}
  \missing{ekman1973cross}
  \missing{hofstede2001culture}
  \missing{matsumoto1989american}
\endrefsection
\endinput

