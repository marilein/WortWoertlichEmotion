Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Curry1967,
abstract = {Twenty-five left-handed and 25 right-handed subjects performed three dichotic listening tasks, two verbal and one non-verbal. Comparisons were made between mean scores obtained at the right and left ears, as well as between the handedness groups. The following results were obtained:1.The mean right ear score was higher than the mean left ear score for both handedness groups on both of the verbal dichotic tasks. This was significant for the right-handed group on both verbal tasks, but for the left-handed group it was significant on only one verbal task.2.The mean left ear score was higher than the mean right ear score for both handedness groups on the non-verbal dichotic task. This betweenears difference was statistically significant for the right-handed group only.3.Comparison of the two handedness groups on each of the three dichotic tests revealed that more left-handed subjects had ear leads which were the reverse of that found for the groups as a whole. This difference between the handedness groups, however, was statistically significant on only one of the dichotic tests.4.The mean left ear score was higher than the mean right ear score for both handedness groups on the non-verbal dichotic task. This betweenears difference was statistically significant for the right-handed group only.5.These data were re-analyzed comparing the size of the absolute between-ears difference scores of those individuals whose ear leads consistently were the reverse of the group as a whole, with subjects who showed no reversals. It was found that the reversal group had smaller mean scores on all three tests, and that this was significant on the two verbal tests. Although more left-handed subjects were found among the reversal group, the data tentatively indicate that the above finding holds true regardless of the handedness of the subjects in the reversal group. The above findings were interpreted as reflecting the different roles of the two cerebral hemispheres, as well as the degree of hemispheric equipotentiality.},
author = {Curry, Frederic K.W.},
doi = {10.1016/s0010-9452(67)80022-4},
issn = {00109452},
journal = {Cortex},
month = {sep},
number = {3},
pages = {343--352},
publisher = {Elsevier BV},
title = {{A Comparison of Left-Handed and Right-Handed Subjects on Verbal and Non-Verbal Dichotic Listening Tasks}},
volume = {3},
year = {1967}
}
@article{Sander2018,
abstract = {This article suggests that methodological and conceptual advancements in affective sciences militate in favor of adopting an appraisal-driven componential approach to further investigate the emotional brain. Here we propose to operationalize this approach by distinguishing five functional networks of the emotional brain: (a) the elicitation network, (b) the expression network, (c) the autonomic reaction network, (d) the action tendency network, and (e) the feeling network, and discuss these networks in the context of the affective neuroscience literature. We also propose that further investigating the “appraising brain” is the royal road to better understand the elicitation network, and may be key to revealing the neural causal mechanisms underlying the emotion process as a whole.},
author = {Sander, David and Grandjean, Didier and Scherer, Klaus R.},
doi = {10.1177/1754073918765653},
file = {:home/mhemmer/Downloads/MA-related/Literatur/SanderGrandjeanSchererEmotionReview2018.pdf:pdf},
issn = {17540739},
journal = {Emotion Review},
keywords = {affective neuroscience,appraisal,brain,emotion},
month = {jul},
number = {3},
pages = {219--231},
publisher = {SAGE Publications Ltd},
title = {{An Appraisal-Driven Componential Approach to the Emotional Brain}},
volume = {10},
year = {2018}
}
@article{Weintraub1981,
abstract = {In addition to grammar and semantics, prosody constitutes a third element of speech. Modulations of prosody can produce alterations in the meaning and affective tone of spoken language. Previous studies have suggested that righthemisphere lesions may selectively disrupt a patient's ability to interpret and express the affective component of prosody. On the other hand, this study shows that the effect of right-hemisphere damage on prosody is more widespread. Thus, when discrimination, repetition, and spontaneous production of nonemotional prosody were tested in nine patients with right-sided brain injuries and ten control subjects without brain damage, the patients were found to be significantly worse than the control subjects in their ability to distinguish and express prosodic features that provide phonemic or emphatic information. These results suggest that right-hemisphere damage may affect prosody in a more general manner than was previously assumed. {\textcopyright} 1981, American Medical Association. All rights reserved.},
author = {Weintraub, Sandra and Mesulam, M. Marsel and Kramer, Laura},
doi = {10.1001/archneur.1981.00510120042004},
issn = {15383687},
journal = {Archives of Neurology},
number = {12},
pages = {742--744},
title = {{Disturbances in Prosody: A Right-Hemisphere Contribution to Language}},
volume = {38},
year = {1981}
}
@article{Ross1979,
abstract = {Two patients lost the ability to impart affective qualities to their speech following lesions in the right hemisphere. Arguments are given to support the idea that the right or “minor” hemisphere has a dominant role in modulating the affective components of speech. The anatomical organization of the cortical areas subserving affective speech in the right hemisphere seem to be similar to the organization of cortical areas subserving propositional speech in the left or “major” hemisphere. {\textcopyright} 1979, American Medical Association. All rights reserved.},
author = {Ross, Elliott D. and Mesulam, Marek Marsel},
doi = {10.1001/archneur.1979.00500390062006},
issn = {15383687},
journal = {Archives of Neurology},
number = {3},
pages = {144--148},
title = {{Dominant Language Functions of the Right Hemisphere?: Prosody and Emotional Gesturing}},
volume = {36},
year = {1979}
}
@article{Behrens1985,
abstract = {Three separate dichotic listening tasks were run to determine ear superiority for stress identification. When subjects were asked to identify stress placement in real word minimal stress pairs (h{\'{o}}tdog vs. hot d{\'{o}}g), they demonstrated a right ear superiority. When these tokens were filtered so that phonetic and semantic information was eliminated and only the stress pattern remained, a different group of subjects showed a left ear advantage. Finally, with nonsense word counterparts to word stress pairs (b{\'{o}}tgog vs. bot g{\'{o}}g) preserving phonetic information but lacking semantic content, no ear asymmetry was found. These results suggest that as the linguistic significance of the stimuli is reduced, thereby lessening the linguistic function of stress, there is a less dominant involvement of the left hemisphere in stress processing. Results are discussed in relation to a theory of a functional integration of prosodic and segmental speech components that is paralleled by a working partnership of left and right hemisphere. {\textcopyright} 1985.},
author = {Behrens, Susan J.},
doi = {10.1016/0093-934X(85)90047-1},
file = {:home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Behrens - 1985 - The perception of stress and lateralization of prosody.pdf:pdf},
issn = {10902155},
journal = {Brain and Language},
month = {nov},
number = {2},
pages = {332--348},
publisher = {Academic Press},
title = {{The perception of stress and lateralization of prosody}},
volume = {26},
year = {1985}
}
@article{VanLancker1973a,
abstract = {In past dichotic listening studies, linguistic stimuli have shown a right ear advantage, implying left hemisphere dominance for language processing, while other stimuli incorporating pitch distinctions have shown no ear perference or a left ear (right hemisphere) advantage. Ear preferences in tone language speakers were compared for 3 sets of stimuli: (a) pitch differences within language stimuli (tone-words in the tone language, Thai); (b) language stimuli without pitch differences (consonant-vowel words on mid-tone); and (c) pitch differences alone (hums). Results from 22 native Thai speakers demonstrate that tone-words and consonant-words are better heard at the right ear, while the hums show no ear effect. Preliminary results on 14 English-speaking Ss suggest that the consonant-words give the usual right ear effect, while the tone-words and the hums do not. It is concluded that pitch discrimination is lateralized to the left hemisphere when the pitch differences are linguistically processed. (47 ref.)},
author = {{Van Lancker}, Diana and Fromkin, Victoria A.},
doi = {10.1016/s0095-4470(19)31414-7},
file = {:home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Lancker, Fromkin - 1973 - Hemispheric specialization for pitch and “tone” Evidence from Thai.pdf:pdf},
issn = {00954470},
journal = {Journal of Phonetics},
month = {apr},
number = {2},
pages = {101--109},
publisher = {Elsevier BV},
title = {{Hemispheric specialization for pitch and “tone”: Evidence from Thai}},
volume = {1},
year = {1973}
}
@article{Sander2018,
abstract = {Modeling emotion processes remains a conceptual and methodological challenge in affective sciences. In responding to the other target articles in this special section on “Emotion and the Brain” and the comments on our article, we address the issue of potentially separate brain networks subserving the functions of the different emotion components. In particular, we discuss the suggested role of component synchronization in producing information integration for the dynamic emergence of a coherent emotion process, as well as the links between incentive salience (“wanting”) and concern-relevance in the elicitation of emotion.},
author = {Sander, David and Grandjean, Didier and Scherer, Klaus R.},
doi = {10.1177/1754073918783257},
issn = {17540739},
journal = {Emotion Review},
keywords = {emotion components,emotional brain,relevance,synchronization},
month = {jul},
number = {3},
pages = {238--241},
publisher = {SAGE Publications Ltd},
title = {{Brain Networks, Emotion Components, and Appraised Relevance}},
volume = {10},
year = {2018}
}
@article{Ackermann2004,
abstract = {Besides a sequence of words, spoken utterances are characterized by prosodic (suprasegmental) qualities such as a distinct into-nation contour ("speech melody"), loudness variations, and a rhythmic structure. In addition to a variety of linguistic and pragmatic functions, these features may reflect a speaker's mood and, thus, contribute, concomitant with facial and gestural movements, to the nonverbal expression of emotions (affective prosody). Clinical studies yielded discrepant data on the cerebral correlates of the processing of affective prosody. Functional imaging provides a more recent approach to the analysis of brain-behaviour relationships. The available investigations indicate two successive stages of the perceptual encoding of affective prosody: (a) predominant right-hemisphere processing of intonation contours within posterior parts of the superior temporal gyrus, (b) evaluation of the conveyed emotion at the level of bilateral orbitofrontal cortex. These findings corroborate and extend the model of a more proficient analysis and short-term storage of tonal information within the right cerebral hemisphere.},
author = {Ackermann, H. and Hertrich, I. and Crodd, W. and Wildgruber, D.},
doi = {10.1055/s-2004-828377},
file = {:home/mhemmer/Downloads/MA-related/Literatur/emotion and prosody/Ackermann{\_}Akt{\_}Neurol{\_}31{\_}446{\_}2004.pdf:pdf},
issn = {03024350},
journal = {Aktuelle Neurologie},
number = {9},
pages = {449--460},
title = {{"Das h{\"{o}}ren von gef{\"{u}}hlen": Funktionell-neuro-anatomische grundlagen der verarbeitung affektiver prosodie}},
volume = {31},
year = {2004}
}
@misc{Schirmer2006,
abstract = {Vocal perception is particularly important for understanding a speaker's emotional state and intentions because, unlike facial perception, it is relatively independent of speaker distance and viewing conditions. The idea, derived from brain lesion studies, that vocal emotional comprehension is a special domain of the right hemisphere has failed to receive consistent support from neuroimaging. This conflict can be reconciled if vocal emotional comprehension is viewed as a multi-step process with individual neural representations. This view reveals a processing chain that proceeds from the ventral auditory pathway to brain structures implicated in cognition and emotion. Thus, vocal emotional comprehension appears to be mediated by bilateral mechanisms anchored within sensory, cognitive and emotional processing systems. {\textcopyright} 2005 Elsevier Ltd. All rights reserved.},
author = {Schirmer, Annett and Kotz, Sonja A.},
booktitle = {Trends in Cognitive Sciences},
doi = {10.1016/j.tics.2005.11.009},
file = {:home/mhemmer/Downloads/MA-related/Literatur/Beyond{\_}the{\_}right{\_}hemisphere{\_}brain{\_}mechan.pdf:pdf},
issn = {13646613},
month = {jan},
number = {1},
pages = {24--30},
title = {{Beyond the right hemisphere: Brain mechanisms mediating vocal emotional processing}},
volume = {10},
year = {2006}
}
@article{Blumstein1974,
abstract = {Two dichotic experiments were conducted to investigate the lateralization of intonation contours. In the first experiment, intonation contours that had been filtered from real speech exemplars of four English sentence types yielded a significant left ear advantage when subjects were given a perceptual matching task. This left ear advantage was maintained when subjects had to identify the same stimuli by their English sentence types. In the second experiment, non-filtered versions of four intonation contours superimposed on a nonsense syllable medium, as well as their filtered equivalents, were presented to subjects, again in a matching task. For both sets of stimuli, a left ear advantage was obtained. Thus, neither the requirements of a linguistic response nor the presence of a phonetic medium succeeded in altering the left ear advantages obtained in the perceptual matching tests. Results from the two experiments suggest that the right hemisphere is directly involved in the perception of intonation contours, and that normal language perception involves the active participation of both cerebral hemispheres. {\textcopyright} 1974, All rights reserved.},
author = {Blumstein, Sheila and Cooper, William E.},
doi = {10.1016/S0010-9452(74)80005-5},
issn = {00109452},
journal = {Cortex},
number = {2},
pages = {146--158},
title = {{Hemispheric Processing of Intonation Contours}},
volume = {10},
year = {1974}
}
@misc{Berckmoes2004,
abstract = {We review the current state of research on the neural bases of emotional speech perception and raise some issues for future research. First, we situate the key questions in this research by discussing the verbal and vocal channels that constitute the emotional message in spoken language. Second, we glance at four hypotheses regarding where in the brain emotional prosody is processed. Finally, we describe relevant results from neuroimaging studies. We conclude that emotional speech perception is most likely accomplished by a bilateral temporofrontal network with subcortical involvement. The exact contribution of each hemisphere seems to depend on the stimulus features and task demands of research paradigms and remains to be determined.},
author = {Berckmoes, Celine and Vingerhoets, Guy},
booktitle = {Current Directions in Psychological Science},
doi = {10.1111/j.0963-7214.2004.00303.x},
file = {:home/mhemmer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berckmoes, Vingerhoets - Unknown - Neural Foundations of Emotional Speech Processing.pdf:pdf},
issn = {09637214},
keywords = {Affective prosody,Emotional speech,Verbal emotion},
number = {5},
pages = {182--185},
title = {{Neural foundations of emotional speech processing}},
url = {https://about.jstor.org/terms},
volume = {13},
year = {2004}
}
